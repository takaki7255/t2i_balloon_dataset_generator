"""
æ–°ã—ã„CFGè¨­å®šã§ã®ç”Ÿæˆçµæœåˆ†æ
"""

import re
import os
from pathlib import Path

def analyze_generation_results():
    """ç”Ÿæˆçµæœã‚’åˆ†æã—ã¦æ–°è¨­å®šã®åŠ¹æœã‚’ç¢ºèª"""
    
    print("=== æ–°CFGè¨­å®šã§ã®ç”Ÿæˆçµæœåˆ†æ ===")
    print()
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    log_file = "../syn_mihiraki1500_dataset01/train_composition_log.txt"
    
    if not os.path.exists(log_file):
        print(f"âŒ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {log_file}")
        return
    
    # ãƒ­ã‚°è§£æ
    balloon_counts = []
    scale_values = []
    width_ratios = []
    final_sizes = []
    
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç”»åƒã”ã¨ã®åˆ†æ
    image_blocks = re.split(r'ç”»åƒ \d+\.png:', content)[1:]  # æœ€åˆã®ç©ºè¦ç´ ã‚’é™¤ã
    
    for block in image_blocks:
        # é…ç½®ã—ãŸå¹ãå‡ºã—æ•°ã‚’å–å¾—
        count_match = re.search(r'é…ç½®ã—ãŸå¹ãå‡ºã—æ•°: (\d+)', block)
        if count_match:
            balloon_counts.append(int(count_match.group(1)))
        
        # å„å¹ãå‡ºã—ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
        scale_matches = re.findall(r'ã‚¹ã‚±ãƒ¼ãƒ«å€¤: ([\d.]+)', block)
        ratio_matches = re.findall(r'ç”»é¢å¹…æ¯”: ([\d.]+)', block)
        size_matches = re.findall(r'æœ€çµ‚ã‚µã‚¤ã‚º: (\d+)x(\d+)', block)
        
        for scale in scale_matches:
            scale_values.append(float(scale))
        
        for ratio in ratio_matches:
            width_ratios.append(float(ratio))
            
        for w, h in size_matches:
            final_sizes.append((int(w), int(h)))
    
    # çµ±è¨ˆè¨ˆç®—
    import numpy as np
    
    print(f"ğŸ“Š **ç”Ÿæˆçµæœçµ±è¨ˆ** (trainç”¨ {len(image_blocks)} ç”»åƒ)")
    print()
    
    print("ğŸ¯ **å¹ãå‡ºã—å€‹æ•°åˆ†æ**")
    if balloon_counts:
        print(f"  å¹³å‡å€‹æ•°: {np.mean(balloon_counts):.1f}å€‹")
        print(f"  æœ€å°-æœ€å¤§: {min(balloon_counts)}-{max(balloon_counts)}å€‹")
        print(f"  ä¸­å¤®å€¤: {np.median(balloon_counts):.1f}å€‹")
        print(f"  å®Ÿéš›ã®çµ±è¨ˆå¹³å‡: 13.1å€‹")
        
        # åˆ†å¸ƒè¡¨ç¤º
        from collections import Counter
        count_dist = Counter(balloon_counts)
        print(f"  åˆ†å¸ƒ:")
        for count in sorted(count_dist.keys()):
            print(f"    {count}å€‹: {count_dist[count]}ç”»åƒ ({count_dist[count]/len(balloon_counts)*100:.1f}%)")
    print()
    
    print("ğŸ“ **ã‚¹ã‚±ãƒ¼ãƒ«å€¤åˆ†æ**")
    if scale_values:
        print(f"  å¹³å‡ã‚¹ã‚±ãƒ¼ãƒ«: {np.mean(scale_values):.3f}")
        print(f"  æœ€å°-æœ€å¤§: {min(scale_values):.3f}-{max(scale_values):.3f}")
        print(f"  ä¸­å¤®å€¤: {np.median(scale_values):.3f}")
        print(f"  æ¨™æº–åå·®: {np.std(scale_values):.3f}")
        print(f"  CFGè¨­å®š: å¹³å‡0.094, ç¯„å›²(0.065-0.110)")
        
        # ç¯„å›²å†…ãƒã‚§ãƒƒã‚¯
        in_range = sum(1 for s in scale_values if 0.065 <= s <= 0.110)
        print(f"  è¨­å®šç¯„å›²å†…: {in_range}/{len(scale_values)} ({in_range/len(scale_values)*100:.1f}%)")
    print()
    
    print("ğŸ“ **ç”»é¢å¹…æ¯”åˆ†æ**")
    if width_ratios:
        print(f"  å¹³å‡å¹…æ¯”: {np.mean(width_ratios):.3f} ({np.mean(width_ratios)*100:.1f}%)")
        print(f"  æœ€å°-æœ€å¤§: {min(width_ratios):.3f}-{max(width_ratios):.3f}")
        print(f"  ä¸­å¤®å€¤: {np.median(width_ratios):.3f}")
        print(f"  å®Ÿéš›ã®çµ±è¨ˆå¹³å‡: 0.094 (9.4%)")
        
        # å®Ÿéš›çµ±è¨ˆã¨ã®æ¯”è¼ƒ
        deviation = abs(np.mean(width_ratios) - 0.094)
        print(f"  çµ±è¨ˆã¨ã®åå·®: {deviation:.3f} ({deviation/0.094*100:.1f}%)")
    print()
    
    print("ğŸ“ **æœ€çµ‚ã‚µã‚¤ã‚ºåˆ†æ**")
    if final_sizes:
        widths = [w for w, h in final_sizes]
        heights = [h for w, h in final_sizes]
        areas = [w * h for w, h in final_sizes]
        
        print(f"  å¹³å‡å¹…: {np.mean(widths):.0f}px")
        print(f"  å¹³å‡é«˜ã•: {np.mean(heights):.0f}px")
        print(f"  å¹³å‡é¢ç©: {np.mean(areas):,.0f}pxÂ²")
        
        # é¢ç©æ¯”è¨ˆç®—ï¼ˆèƒŒæ™¯ã‚µã‚¤ã‚º1536x1024ã¨ã—ã¦ï¼‰
        bg_area = 1536 * 1024
        area_ratios = [area / bg_area for area in areas]
        print(f"  å¹³å‡é¢ç©æ¯”: {np.mean(area_ratios)*100:.3f}%")
        print(f"  å®Ÿéš›ã®çµ±è¨ˆ: 0.877%")
    print()
    
    print("âœ… **è¨­å®šåŠ¹æœã®è©•ä¾¡**")
    
    # å€‹æ•°è©•ä¾¡
    if balloon_counts:
        avg_count = np.mean(balloon_counts)
        if 8 <= avg_count <= 17:
            print("âœ… å€‹æ•°è¨­å®š: çµ±è¨ˆç¯„å›²å†…ã§é©åˆ‡")
        else:
            print("âš ï¸ å€‹æ•°è¨­å®š: çµ±è¨ˆç¯„å›²å¤–")
    
    # ã‚¹ã‚±ãƒ¼ãƒ«è©•ä¾¡
    if scale_values:
        avg_scale = np.mean(scale_values)
        if abs(avg_scale - 0.094) < 0.01:
            print("âœ… ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š: çµ±è¨ˆå¹³å‡ã¨ä¸€è‡´")
        else:
            print("âš ï¸ ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š: çµ±è¨ˆã‹ã‚‰ã®åå·®ã‚ã‚Š")
    
    # å¹…æ¯”è©•ä¾¡
    if width_ratios:
        avg_ratio = np.mean(width_ratios)
        if abs(avg_ratio - 0.094) < 0.01:
            print("âœ… å¹…æ¯”: çµ±è¨ˆå¹³å‡ã¨ä¸€è‡´")
        else:
            print("âš ï¸ å¹…æ¯”: çµ±è¨ˆã‹ã‚‰ã®åå·®ã‚ã‚Š")
    
    print()
    print("ğŸ¯ **æ”¹å–„åŠ¹æœã®ç¢ºèª**")
    print("â€¢ é¢ç©ãƒ™ãƒ¼ã‚¹ãƒªã‚µã‚¤ã‚º + çµ±è¨ˆãƒ™ãƒ¼ã‚¹è¨­å®šã«ã‚ˆã‚Š:")
    print("  - ç¸¦é•·å¹ãå‡ºã—ã®éå¤§ã‚µã‚¤ã‚ºå•é¡Œè§£æ¶ˆ")
    print("  - å®Ÿéš›ã®ãƒãƒ³ã‚¬çµ±è¨ˆã«è¿‘ã„åˆ†å¸ƒå®Ÿç¾")
    print("  - ã‚ˆã‚Šç¾å®Ÿçš„ãªã‚µã‚¤ã‚ºåˆ¶é™")
    print("  - äºˆæ¸¬å¯èƒ½ã§ä¸€è²«ã—ãŸãƒªã‚µã‚¤ã‚ºå‹•ä½œ")

if __name__ == "__main__":
    analyze_generation_results()
