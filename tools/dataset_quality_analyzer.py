"""
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå“è³ªè©•ä¾¡ã¨ç¶™ç¶šçš„æ”¹å–„ã®ãŸã‚ã®åˆ†æãƒ„ãƒ¼ãƒ«
"""

import json
import re
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from pathlib import Path
import os

class DatasetQualityAnalyzer:
    def __init__(self, dataset_path):
        self.dataset_path = Path(dataset_path)
        self.config_path = self.dataset_path / "config.json"
        self.train_log_path = self.dataset_path / "train_composition_log.txt"
        self.val_log_path = self.dataset_path / "val_composition_log.txt"
        
    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def parse_log_file(self, log_file_path):
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦çµ±è¨ˆæƒ…å ±ã‚’æŠ½å‡º"""
        balloon_counts = []
        scale_values = []
        scale_ratios = []
        crop_efficiencies = []
        balloon_sizes = []
        
        if not log_file_path.exists():
            return {}, [], [], [], [], []
            
        with open(log_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å„ç”»åƒã®æƒ…å ±ã‚’æŠ½å‡º
        images = content.split('ç”»åƒ ')[1:]
        
        for image_text in images:
            lines = image_text.split('\n')
            
            # é…ç½®ã—ãŸå¹ãå‡ºã—æ•°ã‚’æŠ½å‡º
            for line in lines:
                if 'é…ç½®ã—ãŸå¹ãå‡ºã—æ•°:' in line:
                    count = int(line.split(':')[1].strip())
                    balloon_counts.append(count)
                    break
            
            # å„å¹ãå‡ºã—ã®è©³ç´°æƒ…å ±ã‚’æŠ½å‡º
            for line in lines:
                if 'ã‚¹ã‚±ãƒ¼ãƒ«å€¤:' in line:
                    scale_val = float(line.split(':')[1].strip())
                    scale_values.append(scale_val)
                elif 'ç”»é¢å¹…æ¯”:' in line:
                    ratio_val = float(line.split(':')[1].strip())
                    scale_ratios.append(ratio_val)
                elif 'ã‚¯ãƒ­ãƒƒãƒ—åŠ¹ç‡:' in line:
                    eff_val = float(line.split(':')[1].strip())
                    crop_efficiencies.append(eff_val)
                elif 'æœ€çµ‚ã‚µã‚¤ã‚º:' in line:
                    size_str = line.split(':')[1].strip()
                    if 'x' in size_str:
                        w, h = map(int, size_str.split('x'))
                        balloon_sizes.append((w, h))
        
        stats = {
            'balloon_count_mean': np.mean(balloon_counts) if balloon_counts else 0,
            'balloon_count_range': (min(balloon_counts), max(balloon_counts)) if balloon_counts else (0, 0),
            'balloon_count_distribution': dict(Counter(balloon_counts)),
            'scale_mean': np.mean(scale_values) if scale_values else 0,
            'scale_range': (min(scale_values), max(scale_values)) if scale_values else (0, 0),
            'ratio_mean': np.mean(scale_ratios) if scale_ratios else 0,
            'ratio_range': (min(scale_ratios), max(scale_ratios)) if scale_ratios else (0, 0),
            'crop_efficiency_mean': np.mean(crop_efficiencies) if crop_efficiencies else 0,
            'total_balloons': len(scale_values),
            'total_images': len(balloon_counts)
        }
        
        return stats, balloon_counts, scale_values, scale_ratios, crop_efficiencies, balloon_sizes
    
    def generate_report(self):
        """åŒ…æ‹¬çš„ãªå“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        config = self.load_config()
        if not config:
            print("âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        print("=" * 80)
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå“è³ªåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {self.dataset_path.name}")
        print(f"ç”Ÿæˆæ™‚åˆ»: {config.get('timestamp', 'N/A')}")
        print("=" * 80)
        
        # è¨­å®šæƒ…å ±ã®è¡¨ç¤º
        cfg = config.get('config', {})
        print(f"\nğŸ”§ è¨­å®šæƒ…å ±:")
        print(f"  å¹ãå‡ºã—å€‹æ•°ç¯„å›²: {cfg.get('NUM_BALLOONS_RANGE', 'N/A')}")
        print(f"  ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š: mode={cfg.get('SCALE_MODE', 'N/A')}, mean={cfg.get('SCALE_MEAN', 'N/A')}")
        print(f"  ã‚¹ã‚±ãƒ¼ãƒ«ç¯„å›²: {cfg.get('SCALE_CLIP', 'N/A')}")
        print(f"  ç›®æ¨™ç”»åƒæ•°: {cfg.get('TARGET_TOTAL_IMAGES', 'N/A')}")
        
        # Train ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
        train_stats, train_counts, train_scales, train_ratios, train_effs, train_sizes = self.parse_log_file(self.train_log_path)
        
        if train_stats:
            print(f"\nğŸ“ˆ TRAIN ãƒ‡ãƒ¼ã‚¿åˆ†æ:")
            print(f"  ç”Ÿæˆç”»åƒæ•°: {train_stats['total_images']}")
            print(f"  ç·å¹ãå‡ºã—æ•°: {train_stats['total_balloons']}")
            print(f"  å¹ãå‡ºã—å€‹æ•°: å¹³å‡{train_stats['balloon_count_mean']:.2f}å€‹ (ç¯„å›²: {train_stats['balloon_count_range'][0]}-{train_stats['balloon_count_range'][1]})")
            print(f"  ç”»é¢å¹…æ¯”: å¹³å‡{train_stats['ratio_mean']:.3f} ({train_stats['ratio_mean']*100:.1f}%)")
            print(f"  ã‚¯ãƒ­ãƒƒãƒ—åŠ¹ç‡: å¹³å‡{train_stats['crop_efficiency_mean']:.3f}")
        
        # Val ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
        val_stats, val_counts, val_scales, val_ratios, val_effs, val_sizes = self.parse_log_file(self.val_log_path)
        
        if val_stats:
            print(f"\nğŸ“Š VAL ãƒ‡ãƒ¼ã‚¿åˆ†æ:")
            print(f"  ç”Ÿæˆç”»åƒæ•°: {val_stats['total_images']}")
            print(f"  ç·å¹ãå‡ºã—æ•°: {val_stats['total_balloons']}")
            print(f"  å¹ãå‡ºã—å€‹æ•°: å¹³å‡{val_stats['balloon_count_mean']:.2f}å€‹ (ç¯„å›²: {val_stats['balloon_count_range'][0]}-{val_stats['balloon_count_range'][1]})")
            print(f"  ç”»é¢å¹…æ¯”: å¹³å‡{val_stats['ratio_mean']:.3f} ({val_stats['ratio_mean']*100:.1f}%)")
            print(f"  ã‚¯ãƒ­ãƒƒãƒ—åŠ¹ç‡: å¹³å‡{val_stats['crop_efficiency_mean']:.3f}")
        
        # å…¨ä½“çµ±è¨ˆ
        all_counts = train_counts + val_counts
        all_ratios = train_ratios + val_ratios
        
        if all_counts and all_ratios:
            print(f"\nğŸŒŸ å…¨ä½“çµ±è¨ˆ:")
            print(f"  å…¨ä½“ç”»åƒæ•°: {len(all_counts)}")
            print(f"  å…¨ä½“å¹ãå‡ºã—æ•°: {len(all_ratios)}")
            print(f"  å¹ãå‡ºã—å€‹æ•°: å¹³å‡{np.mean(all_counts):.2f}å€‹")
            print(f"  ç”»é¢å¹…æ¯”: å¹³å‡{np.mean(all_ratios):.3f} ({np.mean(all_ratios)*100:.1f}%)")
            
            # å®Ÿéš›ã®çµ±è¨ˆã¨ã®æ¯”è¼ƒ
            print(f"\nğŸ” å®Ÿéš›ã®ãƒãƒ³ã‚¬çµ±è¨ˆã¨ã®æ¯”è¼ƒ:")
            print(f"  å®Ÿéš›ã®çµ±è¨ˆ: å¹³å‡12.26å€‹ã€ä¸­å¤®å€¤12å€‹")
            print(f"  ç”Ÿæˆãƒ‡ãƒ¼ã‚¿: å¹³å‡{np.mean(all_counts):.2f}å€‹")
            
            diff = abs(np.mean(all_counts) - 12.26)
            if diff < 0.5:
                print(f"  â†’ âœ… å„ªç§€ (å·®: {diff:.2f}å€‹)")
            elif diff < 1.0:
                print(f"  â†’ âš ï¸ è‰¯å¥½ (å·®: {diff:.2f}å€‹)")
            else:
                print(f"  â†’ âŒ è¦æ”¹å–„ (å·®: {diff:.2f}å€‹)")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ ã®ç¢ºèª
        print(f"\nğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ :")
        train_dir = self.dataset_path / "train"
        val_dir = self.dataset_path / "val"
        
        if train_dir.exists():
            train_imgs = len(list(train_dir.glob("*.png")))
            train_masks = len(list((train_dir / "masks").glob("*.png"))) if (train_dir / "masks").exists() else 0
            print(f"  train: {train_imgs}ç”»åƒ, {train_masks}ãƒã‚¹ã‚¯")
            
        if val_dir.exists():
            val_imgs = len(list(val_dir.glob("*.png")))
            val_masks = len(list((val_dir / "masks").glob("*.png"))) if (val_dir / "masks").exists() else 0
            print(f"  val: {val_imgs}ç”»åƒ, {val_masks}ãƒã‚¹ã‚¯")
    
    def plot_distributions(self):
        """åˆ†å¸ƒã®å¯è¦–åŒ–"""
        train_stats, train_counts, train_scales, train_ratios, _, _ = self.parse_log_file(self.train_log_path)
        val_stats, val_counts, val_scales, val_ratios, _, _ = self.parse_log_file(self.val_log_path)
        
        if not train_counts and not val_counts:
            print("âš ï¸ ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return
            
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle(f'Dataset Quality Analysis - {self.dataset_path.name}', fontsize=16)
        
        # å¹ãå‡ºã—å€‹æ•°åˆ†å¸ƒ
        all_counts = train_counts + val_counts
        if all_counts:
            axes[0, 0].hist(all_counts, bins=range(min(all_counts), max(all_counts)+2), alpha=0.7, edgecolor='black')
            axes[0, 0].axvline(12.26, color='red', linestyle='--', label='Real manga avg (12.26)')
            axes[0, 0].axvline(np.mean(all_counts), color='blue', linestyle='-', label=f'Generated avg ({np.mean(all_counts):.2f})')
            axes[0, 0].set_title('Balloon Count Distribution')
            axes[0, 0].set_xlabel('Number of Balloons')
            axes[0, 0].set_ylabel('Frequency')
            axes[0, 0].legend()
        
        # ç”»é¢å¹…æ¯”åˆ†å¸ƒ
        all_ratios = train_ratios + val_ratios
        if all_ratios:
            axes[0, 1].hist(all_ratios, bins=30, alpha=0.7, edgecolor='black')
            axes[0, 1].axvline(np.mean(all_ratios), color='blue', linestyle='-', label=f'Avg ({np.mean(all_ratios):.3f})')
            axes[0, 1].set_title('Screen Width Ratio Distribution')
            axes[0, 1].set_xlabel('Width Ratio')
            axes[0, 1].set_ylabel('Frequency')
            axes[0, 1].legend()
        
        # ã‚¹ã‚±ãƒ¼ãƒ«å€¤åˆ†å¸ƒ
        all_scales = train_scales + val_scales
        if all_scales:
            axes[1, 0].hist(all_scales, bins=30, alpha=0.7, edgecolor='black')
            axes[1, 0].axvline(np.mean(all_scales), color='blue', linestyle='-', label=f'Avg ({np.mean(all_scales):.3f})')
            axes[1, 0].set_title('Scale Value Distribution')
            axes[1, 0].set_xlabel('Scale Value')
            axes[1, 0].set_ylabel('Frequency')
            axes[1, 0].legend()
        
        # Train vs Val æ¯”è¼ƒ
        if train_counts and val_counts:
            axes[1, 1].hist([train_counts, val_counts], bins=range(min(all_counts), max(all_counts)+2), 
                           alpha=0.7, label=['Train', 'Val'], edgecolor='black')
            axes[1, 1].set_title('Train vs Val Balloon Counts')
            axes[1, 1].set_xlabel('Number of Balloons')
            axes[1, 1].set_ylabel('Frequency')
            axes[1, 1].legend()
        
        plt.tight_layout()
        output_path = self.dataset_path / "quality_analysis.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ“Š åˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: {output_path}")
        plt.show()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    dataset_path = "../syn_mihiraki300_dataset"
    
    if not os.path.exists(dataset_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dataset_path}")
        return
    
    analyzer = DatasetQualityAnalyzer(dataset_path)
    analyzer.generate_report()
    analyzer.plot_distributions()

if __name__ == "__main__":
    main()
