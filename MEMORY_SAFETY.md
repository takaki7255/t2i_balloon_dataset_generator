# 🛡️ 自動メモリ監視＆緊急停止機能

## 概要

`train_unet_split.py`に実装された自動メモリ監視機能により、PCクラッシュを防ぎながら安全に学習できます。

## 🎯 機能

### 1. **自動メモリチェック**
- GPU使用率とRAM使用率を定期的に監視
- 危険な閾値に達したら自動的に警告・停止

### 2. **緊急停止機能**
- メモリ不足を検知したら即座にモデルを保存
- `emergency_epochN.pth` として現在の状態を保存
- メモリをクリアして安全に終了

### 3. **段階的な警告システム**
```
✅ 安全 (GPU<90%, RAM<85%)
⚠️  警告 (GPU 90-92%, RAM 85-88%)  → 警告メッセージ表示
🚨 危険 (GPU>92%, RAM>88%)        → 緊急停止＆保存
```

---

## ⚙️ 監視設定

### チェック頻度
- **エポック開始時**: 毎回チェック
- **Train中**: 10バッチごと
- **Eval中**: 15バッチごと

### 閾値設定（カスタマイズ可能）

```python
# デフォルト設定
check_memory_safety(
    threshold_gpu=0.90,  # GPU: 90%で警告
    threshold_ram=0.85   # RAM: 85%で警告
)

# 緊急停止判定（train_epoch/eval_epoch内）
check_memory_safety(
    threshold_gpu=0.92,  # GPU: 92%で停止
    threshold_ram=0.88   # RAM: 88%で停止
)
```

---

## 📊 使用例

### 実行時の出力例

```
============================================================
System Resource Check
============================================================
RAM: 12.3GB / 32.0GB (38%)
GPU: NVIDIA GeForce RTX 3060
GPU Memory: 1.2GB allocated
GPU Memory: 1.5GB reserved
GPU Total: 12.0GB
============================================================

============================================================
🛡️  自動メモリ監視機能 有効
============================================================
監視閾値:
  - GPU使用率: 90% で警告, 92% で緊急停止
  - RAM使用率: 85% で警告, 88% で緊急停止
チェック頻度:
  - Train: 10バッチごと
  - Eval:  15バッチごと
  - エポック開始時: 毎回
緊急停止時の動作:
  - 現在のモデルを emergency_epochN.pth として保存
  - メモリをクリアして安全に終了
============================================================
```

### 警告が出た場合

```
[Batch 50] ⚠️ GPU使用率が危険: 91.2% (10.94GB/12.0GB)
```

### 緊急停止が発動した場合

```
============================================================
🚨 緊急停止モード
============================================================
理由: ⚠️ GPU使用率が危険: 92.5% (11.10GB/12.0GB)
現在のエポック: 42
✅ 緊急保存完了: emergency_epoch42.pth

安全に終了します...
============================================================
```

---

## 🔧 カスタマイズ方法

### 閾値を変更したい場合

`train_unet_split.py` の以下の部分を編集：

```python
# エポック開始時のチェック（緩め）
is_safe, warning = check_memory_safety(
    threshold_gpu=0.90,  # ← ここを変更
    threshold_ram=0.85   # ← ここを変更
)

# train_epoch/eval_epoch内のチェック（厳しめ）
is_safe, warning = check_memory_safety(
    threshold_gpu=0.92,  # ← ここを変更
    threshold_ram=0.88   # ← ここを変更
)
```

### チェック頻度を変更したい場合

```python
# train_epoch内
if batch_idx % 10 == 0:  # ← 10を変更（小さくすると頻繁にチェック）
    is_safe, warning = check_memory_safety(...)

# eval_epoch内
if batch_idx % 15 == 0:  # ← 15を変更
    is_safe, warning = check_memory_safety(...)
```

---

## 💡 推奨設定

### バッチサイズ別の推奨閾値

| バッチサイズ | GPU閾値 | RAM閾値 | 説明 |
|------------|---------|---------|------|
| 4 | 90%/92% | 85%/88% | 安全（デフォルト） |
| 6 | 88%/90% | 83%/86% | やや厳しめ |
| 8 | 85%/88% | 80%/84% | 厳しめ（推奨） |

### バッチ8で実行する場合の設定例

```python
# より厳しい閾値に変更
check_memory_safety(threshold_gpu=0.85, threshold_ram=0.80)  # 警告
check_memory_safety(threshold_gpu=0.88, threshold_ram=0.84)  # 停止
```

---

## 🚀 緊急停止後の再開方法

### 1. 保存されたモデルを確認

```powershell
ls emergency_*.pth
```

### 2. 設定を調整

- バッチサイズを減らす
- 画像サイズを小さくする（非推奨）
- 監視閾値を厳しくする

### 3. 学習を再開

```python
CFG["RESUME"] = "emergency_epoch42.pth"
```

または `train_unet_split.py` の `RESUME` 設定を変更：

```python
"RESUME": "emergency_epoch42.pth",
```

---

## 📈 効果

### 改善前
```
Batch=8, 500枚 → PCクラッシュ 💥
```

### 改善後（現在）
```
Batch=8, 500枚 → 危険レベルで自動停止 → 緊急保存 ✅
Batch=6, 500枚 → 安全に実行可能（予測） ✅
```

---

## ⚠️ 注意事項

1. **閾値を高くしすぎない**
   - GPU 95%以上 = クラッシュリスク高
   - RAM 90%以上 = システム不安定

2. **緊急停止が頻発する場合**
   - バッチサイズを減らす
   - データセットサイズを減らす
   - より頻繁にメモリクリアする

3. **Windows環境での注意**
   - `num_workers=0` 推奨（メモリリーク防止）
   - `pin_memory=False` 推奨（安定性優先）

---

## 📞 トラブルシューティング

### Q: 緊急停止が発動してしまう
**A**: 閾値を厳しくするか、バッチサイズを減らしてください

### Q: 警告が出るけど学習は続いている
**A**: 正常です。警告レベルなら継続可能です

### Q: 緊急停止したのにモデルが保存されていない
**A**: ファイル書き込み権限を確認してください

---

## 🎓 まとめ

この機能により：
- ✅ PCクラッシュを防止
- ✅ メモリ状態をリアルタイム監視
- ✅ 危険時に自動保存＆安全停止
- ✅ 学習の進捗を失わない

**安心してバッチサイズ6や8で実験できます！**
