"""
ã‚ªãƒãƒãƒˆãƒšã‚’ã‚³ãƒå†…ã«é…ç½®ã™ã‚‹åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µç‰ˆï¼‰

create_syn_onomatopoeia_dataset.pyã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ©Ÿèƒ½ã‚’çµ±åˆã—ã€
ã‚ªãƒãƒãƒˆãƒšã‚’ã‚³ãƒã®å†…å´ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é…ç½®ã™ã‚‹

æ¼«ç”»ã‚ªãƒãƒãƒˆãƒšã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ:
- å›è»¢: Â±30åº¦ï¼ˆæ¼«ç”»ç‰¹æœ‰ã®æ–œã‚é…ç½®ã«å¯¾å¿œï¼‰
- ã‚¹ã‚±ãƒ¼ãƒ«å¤‰å‹•: 0.8ï½1.2å€ï¼ˆã‚µã‚¤ã‚ºã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
- ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”å¤‰æ›´: 0.9ï½1.1å€ï¼ˆç¸¦æ¨ªã®ä¼¸ç¸®ï¼‰
- ã›ã‚“æ–­å¤‰æ›: Â±15åº¦ï¼ˆæ–œä½“åŠ¹æœï¼‰
- é€æ˜åº¦å¤‰åŒ–: 0.7ï½1.0ï¼ˆè–„ã„ã‚ªãƒãƒãƒˆãƒšã«å¯¾å¿œï¼‰
- ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼: ã‚«ãƒ¼ãƒãƒ«(1,3)ï¼ˆå‹•ãã®ãƒ–ãƒ¬è¡¨ç¾ï¼‰
- ãƒ©ãƒ³ãƒ€ãƒ æ¶ˆå»: 5ï½15%ï¼ˆéƒ¨åˆ†çš„ãªæ¬ æã«å¯¾å¿œï¼‰
"""

import cv2
import numpy as np
from pathlib import Path
import os
import random
import shutil
from tqdm import tqdm
import json
from datetime import datetime
import argparse
from typing import List, Tuple, Optional, Dict, Any
from dataclasses import dataclass


@dataclass
class Point:
    """åº§æ¨™ã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹"""
    x: int
    y: int
    
    def __iter__(self):
        return iter((self.x, self.y))


def apply_augmentation(image: np.ndarray, mask: np.ndarray, cfg: dict) -> Tuple[np.ndarray, np.ndarray]:
    """
    æ¼«ç”»ã‚ªãƒãƒãƒˆãƒšã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨
    
    Args:
        image: ã‚ªãƒãƒãƒˆãƒšç”»åƒ
        mask: ãƒã‚¹ã‚¯ç”»åƒ
        cfg: è¨­å®šè¾æ›¸
    
    Returns:
        (augmented_image, augmented_mask): æ‹¡å¼µå¾Œã®ç”»åƒã¨ãƒã‚¹ã‚¯
    """
    aug_cfg = cfg.get("AUGMENTATION", {})
    
    if not aug_cfg.get("ENABLED", False):
        return image, mask
    
    h, w = image.shape[:2]
    
    # 1. å›è»¢ï¼ˆÂ±30åº¦ï¼‰- æ¼«ç”»ã§ã¯æ–œã‚ã«é…ç½®ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„
    if aug_cfg.get("ROTATION", True) and random.random() < aug_cfg.get("ROTATION_PROB", 0.7):
        angle = random.uniform(-30, 30)
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))
        mask = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=0)
    
    # 2. ã‚¹ã‚±ãƒ¼ãƒ«å¤‰å‹•ï¼ˆ0.8ï½1.2å€ï¼‰
    if aug_cfg.get("SCALE", True) and random.random() < aug_cfg.get("SCALE_PROB", 0.5):
        scale = random.uniform(0.8, 1.2)
        new_w, new_h = int(w * scale), int(h * scale)
        image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        mask = cv2.resize(mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)
        
        # å…ƒã®ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹ãŸã‚ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¾ãŸã¯ã‚¯ãƒ­ãƒƒãƒ—
        if new_w > w or new_h > h:
            # ã‚¯ãƒ­ãƒƒãƒ—
            start_x = max(0, (new_w - w) // 2)
            start_y = max(0, (new_h - h) // 2)
            image = image[start_y:start_y+h, start_x:start_x+w]
            mask = mask[start_y:start_y+h, start_x:start_x+w]
        else:
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            pad_x = (w - new_w) // 2
            pad_y = (h - new_h) // 2
            image = cv2.copyMakeBorder(image, pad_y, h-new_h-pad_y, pad_x, w-new_w-pad_x, 
                                      cv2.BORDER_CONSTANT, value=(255, 255, 255))
            mask = cv2.copyMakeBorder(mask, pad_y, h-new_h-pad_y, pad_x, w-new_w-pad_x,
                                     cv2.BORDER_CONSTANT, value=0)
    
    # 3. ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”å¤‰æ›´ï¼ˆ0.9ï½1.1å€ï¼‰- ç¸¦æ¨ªã®ä¼¸ç¸®
    if aug_cfg.get("ASPECT_RATIO", True) and random.random() < aug_cfg.get("ASPECT_PROB", 0.3):
        aspect_x = random.uniform(0.9, 1.1)
        aspect_y = random.uniform(0.9, 1.1)
        new_w, new_h = int(w * aspect_x), int(h * aspect_y)
        image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        mask = cv2.resize(mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)
        image = cv2.resize(image, (w, h), interpolation=cv2.INTER_LINEAR)
        mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)
    
    # 4. ã›ã‚“æ–­å¤‰æ›ï¼ˆÂ±15åº¦ï¼‰- æ–œä½“åŠ¹æœ
    if aug_cfg.get("SHEAR", True) and random.random() < aug_cfg.get("SHEAR_PROB", 0.4):
        shear = random.uniform(-0.3, 0.3)  # tan(15åº¦) â‰ˆ 0.27
        M = np.float32([[1, shear, 0], [0, 1, 0]])
        image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))
        mask = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=0)
    
    # 5. é€æ˜åº¦å¤‰åŒ–ï¼ˆ0.7ï½1.0ï¼‰- è–„ã„ã‚ªãƒãƒãƒˆãƒšã«å¯¾å¿œ
    if aug_cfg.get("ALPHA", True) and random.random() < aug_cfg.get("ALPHA_PROB", 0.5):
        alpha = random.uniform(0.7, 1.0)
        # ãƒã‚¹ã‚¯ã¯å¤‰æ›´ã›ãšã€ç”»åƒã®ã¿é€æ˜åº¦ã‚’å¤‰æ›´ï¼ˆç™½èƒŒæ™¯ã«è¿‘ã¥ã‘ã‚‹ï¼‰
        white_bg = np.ones_like(image) * 255
        image = (image * alpha + white_bg * (1 - alpha)).astype(np.uint8)
    
    # 6. ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ï¼ˆå‹•ãã®ãƒ–ãƒ¬è¡¨ç¾ï¼‰
    if aug_cfg.get("BLUR", True) and random.random() < aug_cfg.get("BLUR_PROB", 0.3):
        kernel_size = random.choice([1, 3])
        if kernel_size > 1:
            image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    
    # 7. ãƒ©ãƒ³ãƒ€ãƒ æ¶ˆå»ï¼ˆ5ï½15%ï¼‰- éƒ¨åˆ†çš„ãªæ¬ æ
    if aug_cfg.get("RANDOM_ERASING", True) and random.random() < aug_cfg.get("ERASING_PROB", 0.3):
        erase_ratio = random.uniform(0.05, 0.15)
        erase_h = int(h * np.sqrt(erase_ratio))
        erase_w = int(w * np.sqrt(erase_ratio))
        
        if erase_h > 0 and erase_w > 0:
            top = random.randint(0, max(0, h - erase_h))
            left = random.randint(0, max(0, w - erase_w))
            image[top:top+erase_h, left:left+erase_w] = 255  # ç™½ã§æ¶ˆå»
            mask[top:top+erase_h, left:left+erase_w] = 0     # ãƒã‚¹ã‚¯ã‚‚æ¶ˆå»
    
    return image, mask


def regions_overlap(region1: tuple, region2: tuple) -> bool:
    """2ã¤ã®é ˜åŸŸãŒé‡è¤‡ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    x1_min, y1_min, x1_max, y1_max = region1
    x2_min, y2_min, x2_max, y2_max = region2
    
    return not (x1_max <= x2_min or x2_max <= x1_min or y1_max <= y2_min or y2_max <= y1_min)


def calculate_overlap_area(region1: tuple, region2: tuple) -> int:
    """2ã¤ã®é ˜åŸŸã®é‡è¤‡é¢ç©ã‚’è¨ˆç®—"""
    x1_min, y1_min, x1_max, y1_max = region1
    x2_min, y2_min, x2_max, y2_max = region2
    
    overlap_x_min = max(x1_min, x2_min)
    overlap_y_min = max(y1_min, y2_min)
    overlap_x_max = min(x1_max, x2_max)
    overlap_y_max = min(y1_max, y2_max)
    
    if overlap_x_max <= overlap_x_min or overlap_y_max <= overlap_y_min:
        return 0
    
    return (overlap_x_max - overlap_x_min) * (overlap_y_max - overlap_y_min)


def get_mask_bbox(mask):
    """ãƒã‚¹ã‚¯ã®éã‚¼ãƒ­é ˜åŸŸã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—"""
    coords = np.column_stack(np.where(mask > 0))
    
    if len(coords) == 0:
        return 0, 0, mask.shape[1], mask.shape[0]
    
    y_min, x_min = coords.min(axis=0)
    y_max, x_max = coords.max(axis=0)
    
    return x_min, y_min, x_max - x_min + 1, y_max - y_min + 1


def crop_onomatopoeia_and_mask(onomatopoeia, mask):
    """ãƒã‚¹ã‚¯ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦ã‚ªãƒãƒãƒˆãƒšç”»åƒã¨ãƒã‚¹ã‚¯ã‚’ã‚¯ãƒ­ãƒƒãƒ—"""
    x, y, w, h = get_mask_bbox(mask)
    
    cropped_onomatopoeia = onomatopoeia[y:y+h, x:x+w]
    cropped_mask = mask[y:y+h, x:x+w]
    
    return cropped_onomatopoeia, cropped_mask, (x, y, w, h)


def detect_panels_simple(image: np.ndarray, 
                        area_ratio_threshold: float = 0.85,
                        min_area: int = 10000) -> List[Tuple[np.ndarray, Tuple[int, int, int, int]]]:
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªäºŒå€¤åŒ–ãƒ»è¼ªéƒ­æŠ½å‡ºã«ã‚ˆã‚‹ã‚³ãƒæ¤œå‡º
    
    Args:
        image: å…¥åŠ›ç”»åƒï¼ˆã‚«ãƒ©ãƒ¼ï¼‰
        area_ratio_threshold: è¼ªéƒ­é¢ç©/ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹é¢ç©ã®é–¾å€¤
        min_area: æœ€å°ã‚³ãƒé¢ç©
    
    Returns:
        List[(panel_mask, bbox)]: ãƒ‘ãƒãƒ«ãƒã‚¹ã‚¯ã€ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆ
    """
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # äºŒå€¤åŒ–ï¼ˆOtsuã®è‡ªå‹•é–¾å€¤ï¼‰
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    
    # ãƒã‚¤ã‚ºé™¤å»ï¼ˆãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—ï¼‰
    kernel = np.ones((3, 3), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # è¼ªéƒ­æ¤œå‡º
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    panels = []
    for contour in contours:
        area = cv2.contourArea(contour)
        
        if area < min_area:
            continue
        
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        x, y, w, h = cv2.boundingRect(contour)
        bbox_area = w * h
        
        # é¢ç©æ¯”ãƒã‚§ãƒƒã‚¯ï¼ˆçŸ©å½¢ã«è¿‘ã„å½¢çŠ¶ã®ã¿ï¼‰
        if area / bbox_area < area_ratio_threshold:
            continue
        
        # ãƒ‘ãƒãƒ«ãƒã‚¹ã‚¯ã‚’ä½œæˆ
        panel_mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.drawContours(panel_mask, [contour], -1, 255, -1)
        
        panels.append((panel_mask, (x, y, w, h)))
    
    return panels


def sample_scale(page_w: int, page_h: int, cfg: dict) -> float:
    """èƒŒæ™¯ç”»åƒï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰ã‚µã‚¤ã‚ºã«å¿œã˜ãŸã‚¹ã‚±ãƒ¼ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
    # èƒŒæ™¯ç”»åƒé¢ç©ã«å¯¾ã™ã‚‹æ¯”ç‡ã¨ã—ã¦è¨ˆç®—
    page_area = page_w * page_h
    scale_range = cfg.get("SCALE_RANGE", (0.005, 0.03))
    return random.uniform(*scale_range)


def calculate_onomatopoeia_size(crop_w: int, crop_h: int, page_w: int, page_h: int,
                                target_scale: float, panel_w: int = None, panel_h: int = None,
                                mask: np.ndarray = None) -> tuple:
    """ã‚ªãƒãƒãƒˆãƒšã®ãƒªã‚µã‚¤ã‚ºã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    
    Args:
        crop_w, crop_h: ã‚¯ãƒ­ãƒƒãƒ—å¾Œã®ã‚ªãƒãƒãƒˆãƒšã‚µã‚¤ã‚º
        page_w, page_h: èƒŒæ™¯ç”»åƒï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰ã®ã‚µã‚¤ã‚º
        target_scale: èƒŒæ™¯ç”»åƒé¢ç©ã«å¯¾ã™ã‚‹ç›®æ¨™ã‚¹ã‚±ãƒ¼ãƒ«
        panel_w, panel_h: ãƒ‘ãƒãƒ«ã‚µã‚¤ã‚ºï¼ˆé…ç½®å…ˆã®åˆ¶é™ç”¨ã€Noneãªã‚‰ãƒšãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’ä½¿ç”¨ï¼‰
        mask: ãƒã‚¹ã‚¯ç”»åƒ
    
    Returns:
        (new_w, new_h): ãƒªã‚µã‚¤ã‚ºå¾Œã®ã‚µã‚¤ã‚º
    """
    # èƒŒæ™¯ç”»åƒé¢ç©ã‚’åŸºæº–ã«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    page_area = page_w * page_h
    target_area = page_area * target_scale
    
    # ãƒã‚¹ã‚¯é ˜åŸŸã‚’è€ƒæ…®
    if mask is not None:
        mask_pixels = np.count_nonzero(mask)
        crop_pixels = crop_w * crop_h
        mask_ratio = mask_pixels / crop_pixels if crop_pixels > 0 else 1.0
    else:
        mask_ratio = 1.0
    
    aspect_ratio = crop_h / crop_w
    
    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ãŸç†æƒ³ã‚µã‚¤ã‚º
    ideal_w = int(np.sqrt(target_area / aspect_ratio))
    ideal_h = int(np.sqrt(target_area * aspect_ratio))
    
    # ãƒ‘ãƒãƒ«ã‚µã‚¤ã‚ºã®åˆ¶é™ï¼ˆãƒ‘ãƒãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ãã®50%ä»¥å†…ã€ãªã‘ã‚Œã°ãƒšãƒ¼ã‚¸ã®30%ä»¥å†…ï¼‰
    limit_w = panel_w if panel_w else page_w
    limit_h = panel_h if panel_h else page_h
    max_w = int(limit_w * 0.5)
    max_h = int(limit_h * 0.5)
    
    scale_by_w = max_w / ideal_w if ideal_w > max_w else 1.0
    scale_by_h = max_h / ideal_h if ideal_h > max_h else 1.0
    adjust_scale = min(scale_by_w, scale_by_h)
    
    new_w = int(ideal_w * adjust_scale)
    new_h = int(ideal_h * adjust_scale)
    
    # æœ€å°ã‚µã‚¤ã‚ºç¢ºä¿
    new_w = max(new_w, 20)
    new_h = max(new_h, 20)
    
    return new_w, new_h


def sample_num_onomatopoeia_for_page(cfg: dict, max_available: int) -> int:
    """ãƒšãƒ¼ã‚¸å…¨ä½“ã«é…ç½®ã™ã‚‹ã‚ªãƒãƒãƒˆãƒšå€‹æ•°ã‚’çµ±è¨ˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    
    çµ±è¨ˆãƒ‡ãƒ¼ã‚¿:
        å¹³å‡: 7.2å€‹, ä¸­å¤®å€¤: 6å€‹, æ¨™æº–åå·®: 6.1
        25ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: 3å€‹, 75ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: 10å€‹
        æœ€å°: 1å€‹, æœ€å¤§: 82å€‹
    
    Args:
        cfg: è¨­å®šè¾æ›¸
        max_available: åˆ©ç”¨å¯èƒ½ãªã‚ªãƒãƒãƒˆãƒšã®æœ€å¤§æ•°
    
    Returns:
        é…ç½®ã™ã‚‹ã‚ªãƒãƒãƒˆãƒšã®å€‹æ•°
    """
    # çµ±è¨ˆã«åŸºã¥ãæ­£è¦åˆ†å¸ƒã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    mean = cfg.get("NUM_ONOMATOPOEIA_MEAN", 7.0)
    std = cfg.get("NUM_ONOMATOPOEIA_STD", 6.0)
    min_count = cfg.get("NUM_ONOMATOPOEIA_MIN", 1)
    max_count = cfg.get("NUM_ONOMATOPOEIA_MAX", 20)
    
    # æ­£è¦åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦æ•´æ•°åŒ–
    n = int(round(random.gauss(mean, std)))
    
    # ç¯„å›²å†…ã«ã‚¯ãƒªãƒƒãƒ—
    n = max(min_count, min(max_count, n))
    n = min(max_available, n)
    
    if n <= 0:
        n = 1
    return n


def place_single_onomatopoeia(result_img: np.ndarray, result_mask: np.ndarray,
                              onomatopoeia_path: str, mask_path: str,
                              panel_mask: np.ndarray, panel_bbox: tuple,
                              occupied_regions: list, cfg: dict,
                              page_size: tuple = None) -> Optional[dict]:
    """1ã¤ã®ã‚ªãƒãƒãƒˆãƒšã‚’ãƒ‘ãƒãƒ«å†…ã«é…ç½®
    
    Args:
        result_img: çµæœç”»åƒï¼ˆin-placeæ›´æ–°ï¼‰
        result_mask: çµæœãƒã‚¹ã‚¯ï¼ˆin-placeæ›´æ–°ï¼‰
        onomatopoeia_path: ã‚ªãƒãƒãƒˆãƒšç”»åƒãƒ‘ã‚¹
        mask_path: ãƒã‚¹ã‚¯ç”»åƒãƒ‘ã‚¹
        panel_mask: ãƒ‘ãƒãƒ«ãƒã‚¹ã‚¯
        panel_bbox: ãƒ‘ãƒãƒ«ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ (x, y, w, h)
        occupied_regions: æ—¢ã«é…ç½®æ¸ˆã¿ã®é ˜åŸŸãƒªã‚¹ãƒˆï¼ˆin-placeæ›´æ–°ï¼‰
        cfg: è¨­å®šè¾æ›¸
        page_size: èƒŒæ™¯ç”»åƒï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰ã®ã‚µã‚¤ã‚º (page_w, page_h)
    
    Returns:
        é…ç½®æˆåŠŸæ™‚ã¯ã‚ªãƒãƒãƒˆãƒšæƒ…å ±ã®è¾æ›¸ã€å¤±æ•—æ™‚ã¯None
    """
    x, y, w, h = panel_bbox
    
    # èƒŒæ™¯ç”»åƒã‚µã‚¤ã‚ºï¼ˆæŒ‡å®šãŒãªã‘ã‚Œã°result_imgã®ã‚µã‚¤ã‚ºã‚’ä½¿ç”¨ï¼‰
    if page_size is None:
        page_h, page_w = result_img.shape[:2]
    else:
        page_w, page_h = page_size
    
    # ã‚ªãƒãƒãƒˆãƒšã¨ãƒã‚¹ã‚¯èª­ã¿è¾¼ã¿
    onomatopoeia = cv2.imread(onomatopoeia_path, cv2.IMREAD_COLOR)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    
    if onomatopoeia is None or mask is None:
        return None
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨
    onomatopoeia, mask = apply_augmentation(onomatopoeia, mask, cfg)
    
    # ãƒã‚¹ã‚¯ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã§ã‚¯ãƒ­ãƒƒãƒ—
    cropped_onomatopoeia, cropped_mask, bbox = crop_onomatopoeia_and_mask(onomatopoeia, mask)
    
    if cropped_onomatopoeia.size == 0 or cropped_mask.size == 0:
        return None
    
    crop_h, crop_w = cropped_onomatopoeia.shape[:2]
    
    # ã‚¹ã‚±ãƒ¼ãƒ«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆèƒŒæ™¯ç”»åƒã‚µã‚¤ã‚ºã‚’åŸºæº–ï¼‰
    onomatopoeia_scale = sample_scale(page_w, page_h, cfg)
    
    # ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆèƒŒæ™¯ç”»åƒã‚µã‚¤ã‚ºã‚’åŸºæº–ã€ãƒ‘ãƒãƒ«ã‚µã‚¤ã‚ºã§åˆ¶é™ï¼‰
    new_w, new_h = calculate_onomatopoeia_size(
        crop_w, crop_h, page_w, page_h, onomatopoeia_scale,
        panel_w=w, panel_h=h,
        mask=cropped_mask
    )
    
    # ãƒ‘ãƒãƒ«ã‚µã‚¤ã‚ºã‚’è¶…ãˆã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if new_w >= w or new_h >= h:
        return None
    
    # ãƒªã‚µã‚¤ã‚º
    onomatopoeia_resized = cv2.resize(cropped_onomatopoeia, (new_w, new_h))
    mask_resized = cv2.resize(cropped_mask, (new_w, new_h))
    
    # ãƒ‘ãƒãƒ«å†…ã§ã®é…ç½®ä½ç½®ã‚’æ¢ã™
    best_position = None
    min_overlap_ratio = float('inf')
    
    max_attempts = cfg.get("MAX_ATTEMPTS", 100)
    for attempt in range(max_attempts):
        # ãƒ‘ãƒãƒ«å†…ã®ãƒ©ãƒ³ãƒ€ãƒ ä½ç½®
        if w - new_w <= 0 or h - new_h <= 0:
            break
        
        local_x = random.randint(0, w - new_w)
        local_y = random.randint(0, h - new_h)
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«åº§æ¨™
        global_x = x + local_x
        global_y = y + local_y
        
        # ãƒ‘ãƒãƒ«ãƒã‚¹ã‚¯å†…ã‹ãƒã‚§ãƒƒã‚¯
        center_x = global_x + new_w // 2
        center_y = global_y + new_h // 2
        
        if center_y >= panel_mask.shape[0] or center_x >= panel_mask.shape[1]:
            continue
        
        if panel_mask[center_y, center_x] == 0:
            continue
        
        # æ–°ã—ã„é ˜åŸŸ
        new_region = (global_x, global_y, global_x + new_w, global_y + new_h)
        
        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        max_overlap_ratio = 0
        for occupied in occupied_regions:
            if regions_overlap(new_region, occupied):
                overlap_area = calculate_overlap_area(new_region, occupied)
                new_area = new_w * new_h
                overlap_ratio = overlap_area / new_area
                max_overlap_ratio = max(max_overlap_ratio, overlap_ratio)
        
        # é‡è¤‡ãŒå°‘ãªã„å ´åˆã¯é…ç½®
        if max_overlap_ratio <= 0.15:
            best_position = (global_x, global_y)
            break
        
        if max_overlap_ratio < min_overlap_ratio:
            min_overlap_ratio = max_overlap_ratio
            best_position = (global_x, global_y)
    
    # é…ç½®å®Ÿè¡Œ
    if best_position is None:
        return None
    
    global_x, global_y = best_position
    
    # åˆæˆ
    mask_norm = mask_resized.astype(np.float32) / 255.0
    mask_3ch = cv2.merge([mask_norm, mask_norm, mask_norm])
    
    # èƒŒæ™¯ç”»åƒã®è©²å½“é ˜åŸŸ
    bg_region = result_img[global_y:global_y+new_h, global_x:global_x+new_w]
    
    # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
    blended = onomatopoeia_resized.astype(np.float32) * mask_3ch + bg_region.astype(np.float32) * (1 - mask_3ch)
    result_img[global_y:global_y+new_h, global_x:global_x+new_w] = blended.astype(np.uint8)
    
    # ãƒã‚¹ã‚¯åˆæˆ
    result_mask[global_y:global_y+new_h, global_x:global_x+new_w] = np.maximum(
        result_mask[global_y:global_y+new_h, global_x:global_x+new_w], mask_resized)
    
    # é…ç½®æ¸ˆã¿é ˜åŸŸã«è¿½åŠ 
    new_region = (global_x, global_y, global_x + new_w, global_y + new_h)
    occupied_regions.append(new_region)
    
    return {
        "onomatopoeia_file": Path(onomatopoeia_path).name,
        "final_size": f"{new_w}x{new_h}",
        "position": f"({global_x},{global_y})",
        "scale": f"{onomatopoeia_scale:.6f}",
    }


def composite_onomatopoeia_on_page(page_img: np.ndarray, panels: list,
                                   onomatopoeia_pairs: list, cfg: dict) -> tuple:
    """ãƒšãƒ¼ã‚¸å…¨ä½“ã«ã‚ªãƒãƒãƒˆãƒšã‚’é…ç½®
    
    1. æœ€åˆã«ãƒšãƒ¼ã‚¸å…¨ä½“ã«é…ç½®ã™ã‚‹ã‚ªãƒãƒãƒˆãƒšå€‹æ•°ã‚’çµ±è¨ˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    2. ãƒ‘ãƒãƒ«æ¤œå‡ºæ™‚ï¼šæ¤œå‡ºã•ã‚ŒãŸãƒ‘ãƒãƒ«ã«åˆ†æ•£ã—ã¦é…ç½®
    3. ãƒ‘ãƒãƒ«æœªæ¤œå‡ºæ™‚ï¼šãƒšãƒ¼ã‚¸å…¨ä½“ã«ãƒ©ãƒ³ãƒ€ãƒ é…ç½®
    
    Args:
        page_img: ãƒšãƒ¼ã‚¸ç”»åƒ
        panels: æ¤œå‡ºã•ã‚ŒãŸãƒ‘ãƒãƒ«ã®ãƒªã‚¹ãƒˆ [(panel_mask, bbox), ...]
        onomatopoeia_pairs: ã‚ªãƒãƒãƒˆãƒšã¨ãƒã‚¹ã‚¯ã®ãƒšã‚¢ã®ãƒªã‚¹ãƒˆ
        cfg: è¨­å®šè¾æ›¸
    
    Returns:
        (result_img, result_mask, onomatopoeia_details, placement_info)
    """
    h, w = page_img.shape[:2]
    page_size = (w, h)  # èƒŒæ™¯ç”»åƒã‚µã‚¤ã‚º
    result_img = page_img.copy()
    result_mask = np.zeros((h, w), dtype=np.uint8)
    
    # ãƒšãƒ¼ã‚¸å…¨ä½“ã«é…ç½®ã™ã‚‹ã‚ªãƒãƒãƒˆãƒšå€‹æ•°ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    target_count = sample_num_onomatopoeia_for_page(cfg, len(onomatopoeia_pairs))
    
    # ã‚ªãƒãƒãƒˆãƒšã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦é¸æŠ
    selected_pairs = random.sample(onomatopoeia_pairs, min(target_count * 2, len(onomatopoeia_pairs)))
    
    occupied_regions = []
    onomatopoeia_details = []
    placed_count = 0
    pair_idx = 0
    
    # ãƒšãƒ¼ã‚¸å…¨ä½“ç”¨ã®ãƒã‚¹ã‚¯ã¨bboxï¼ˆãƒ©ãƒ³ãƒ€ãƒ é…ç½®ç”¨ï¼‰
    full_mask = np.ones((h, w), dtype=np.uint8) * 255
    full_bbox = (0, 0, w, h)
    
    if len(panels) == 0:
        # ãƒ‘ãƒãƒ«æœªæ¤œå‡ºï¼šãƒšãƒ¼ã‚¸å…¨ä½“ã«ãƒ©ãƒ³ãƒ€ãƒ é…ç½®
        for onomatopoeia_path, mask_path in selected_pairs:
            if placed_count >= target_count:
                break
            
            detail = place_single_onomatopoeia(
                result_img, result_mask,
                onomatopoeia_path, mask_path,
                full_mask, full_bbox,
                occupied_regions, cfg,
                page_size=page_size
            )
            
            if detail is not None:
                detail["panel"] = "å…¨ä½“"
                onomatopoeia_details.append(detail)
                placed_count += 1
        
        placement_info = {
            "mode": "full_page",
            "panels_detected": 0,
            "target_count": target_count,
            "placed_count": placed_count
        }
    else:
        # ãƒ‘ãƒãƒ«æ¤œå‡ºï¼šå„ãƒ‘ãƒãƒ«ã«1ã€œ2å€‹ãšã¤é…ç½®ã€æ®‹ã‚Šã¯ãƒ©ãƒ³ãƒ€ãƒ é…ç½®
        max_per_panel = cfg.get("MAX_ONOMATOPOEIA_PER_PANEL", 2)
        panel_placement_count = {}  # å„ãƒ‘ãƒãƒ«ã¸ã®é…ç½®æ•°ã‚’è¨˜éŒ²
        
        # Phase 1: å„ãƒ‘ãƒãƒ«ã«æœ€å¤§max_per_panelå€‹ã¾ã§é…ç½®
        for panel_idx, (panel_mask, bbox) in enumerate(panels):
            if placed_count >= target_count:
                break
            if pair_idx >= len(selected_pairs):
                break
            
            panel_placement_count[panel_idx] = 0
            
            # ã“ã®ãƒ‘ãƒãƒ«ã«æœ€å¤§max_per_panelå€‹é…ç½®ã‚’è©¦ã¿ã‚‹
            attempts_for_panel = 0
            while (panel_placement_count[panel_idx] < max_per_panel 
                   and placed_count < target_count 
                   and pair_idx < len(selected_pairs)
                   and attempts_for_panel < max_per_panel * 2):
                
                onomatopoeia_path, mask_path = selected_pairs[pair_idx]
                pair_idx += 1
                attempts_for_panel += 1
                
                detail = place_single_onomatopoeia(
                    result_img, result_mask,
                    onomatopoeia_path, mask_path,
                    panel_mask, bbox,
                    occupied_regions, cfg,
                    page_size=page_size
                )
                
                if detail is not None:
                    detail["panel"] = f"panel_{panel_idx}"
                    onomatopoeia_details.append(detail)
                    placed_count += 1
                    panel_placement_count[panel_idx] += 1
        
        # Phase 2: ç›®æ¨™æ•°ã«é”ã—ã¦ã„ãªã‘ã‚Œã°ã€ãƒšãƒ¼ã‚¸å…¨ä½“ã«ãƒ©ãƒ³ãƒ€ãƒ é…ç½®
        while placed_count < target_count and pair_idx < len(selected_pairs):
            onomatopoeia_path, mask_path = selected_pairs[pair_idx]
            pair_idx += 1
            
            detail = place_single_onomatopoeia(
                result_img, result_mask,
                onomatopoeia_path, mask_path,
                full_mask, full_bbox,
                occupied_regions, cfg,
                page_size=page_size
            )
            
            if detail is not None:
                detail["panel"] = "random"
                onomatopoeia_details.append(detail)
                placed_count += 1
        
        placement_info = {
            "mode": "panels_and_random",
            "panels_detected": len(panels),
            "target_count": target_count,
            "placed_count": placed_count,
            "placed_in_panels": sum(panel_placement_count.values()),
            "placed_random": placed_count - sum(panel_placement_count.values())
        }
    
    return result_img, result_mask, onomatopoeia_details, placement_info

def split_onomatopoeia(onomatopoeia_mask_pairs: list, train_ratio: float = 0.8, seed: int = 42) -> tuple:
    """ã‚ªãƒãƒãƒˆãƒšã‚’trainç”¨ã¨valç”¨ã«åˆ†å‰²"""
    random.seed(seed)
    shuffled_pairs = onomatopoeia_mask_pairs.copy()
    random.shuffle(shuffled_pairs)
    
    n = len(shuffled_pairs)
    train_count = int(n * train_ratio)
    
    train_pairs = shuffled_pairs[:train_count]
    val_pairs = shuffled_pairs[train_count:]
    
    return train_pairs, val_pairs


def generate_dataset_split(page_files: list, onomatopoeia_pairs: list,
                          output_dir: str, mask_output_dir: str, split_name: str,
                          target_count: int, cfg: dict, final_output_dir: str = None) -> int:
    """æŒ‡å®šã•ã‚ŒãŸsplitï¼ˆtrainã¾ãŸã¯valï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆ
    
    1ãƒšãƒ¼ã‚¸ã‹ã‚‰1æšã®ç”»åƒã‚’ç”Ÿæˆã—ã€çµ±è¨ˆã«å¿œã˜ãŸã‚ªãƒãƒãƒˆãƒšå€‹æ•°ã‚’é…ç½®ã™ã‚‹
    """
    print(f"\n=== {split_name} ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆé–‹å§‹ ===")
    print(f"ç›®æ¨™ç”»åƒæ•°: {target_count}")
    print(f"ãƒšãƒ¼ã‚¸ç”»åƒæ•°: {len(page_files)}")
    print(f"åˆ©ç”¨å¯èƒ½ã‚ªãƒãƒãƒˆãƒšæ•°: {len(onomatopoeia_pairs)}")
    
    if final_output_dir:
        log_file_path = os.path.join(final_output_dir, f"{split_name}_composition_log.txt")
    else:
        log_file_path = os.path.join(output_dir, f"{split_name}_composition_log.txt")
    
    current_number = 1
    success_count = 0
    page_idx = 0
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åˆæœŸåŒ–
    with open(log_file_path, 'w', encoding='utf-8') as log_file:
        log_file.write(f"=== {split_name.upper()} ãƒ‘ãƒãƒ«å†…ã‚ªãƒãƒãƒˆãƒšãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆæˆãƒ­ã‚° ===\n")
        log_file.write(f"ç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        log_file.write(f"ç›®æ¨™ç”»åƒæ•°: {target_count}\n")
        log_file.write(f"ãƒšãƒ¼ã‚¸ç”»åƒæ•°: {len(page_files)}\n")
        log_file.write(f"åˆ©ç”¨å¯èƒ½ã‚ªãƒãƒãƒˆãƒšæ•°: {len(onomatopoeia_pairs)}\n")
        log_file.write("=" * 80 + "\n\n")
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    pbar = tqdm(total=target_count, desc=f"{split_name} ç”Ÿæˆä¸­", unit="img")
    
    while success_count < target_count:
        page_path = page_files[page_idx % len(page_files)]
        page_name = Path(page_path).stem
        
        try:
            # ãƒšãƒ¼ã‚¸ç”»åƒèª­ã¿è¾¼ã¿
            page_img = cv2.imread(page_path, cv2.IMREAD_COLOR)
            if page_img is None:
                raise FileNotFoundError(f"ãƒšãƒ¼ã‚¸ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {page_path}")
            
            h, w = page_img.shape[:2]
            
            # ãƒ‘ãƒãƒ«æ¤œå‡º
            panels = detect_panels_simple(page_img, 
                                        area_ratio_threshold=cfg.get("PANEL_AREA_RATIO_THRESHOLD", 0.85),
                                        min_area=cfg.get("PANEL_MIN_AREA", 10000))
            
            # ãƒšãƒ¼ã‚¸å…¨ä½“ã«ã‚ªãƒãƒãƒˆãƒšã‚’é…ç½®ï¼ˆ1ãƒšãƒ¼ã‚¸=1ç”»åƒï¼‰
            result_img, result_mask, onomatopoeia_details, placement_info = composite_onomatopoeia_on_page(
                page_img, panels, onomatopoeia_pairs, cfg
            )
            
            if len(onomatopoeia_details) > 0:
                # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                output_img_path = os.path.join(output_dir, f"{current_number:03d}.png")
                output_mask_path = os.path.join(mask_output_dir, f"{current_number:03d}_mask.png")
                
                cv2.imwrite(output_img_path, result_img)
                cv2.imwrite(output_mask_path, result_mask)
                
                # ãƒ­ã‚°è¨˜éŒ²
                with open(log_file_path, 'a', encoding='utf-8') as log_file:
                    log_file.write(f"ç”»åƒ {current_number:03d}.png:\n")
                    log_file.write(f"  ãƒšãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«: {Path(page_path).name}\n")
                    log_file.write(f"  ç”»åƒã‚µã‚¤ã‚º: {w}x{h}\n")
                    log_file.write(f"  é…ç½®ãƒ¢ãƒ¼ãƒ‰: {placement_info['mode']}\n")
                    log_file.write(f"  æ¤œå‡ºãƒ‘ãƒãƒ«æ•°: {placement_info['panels_detected']}\n")
                    log_file.write(f"  ç›®æ¨™ã‚ªãƒãƒãƒˆãƒšæ•°: {placement_info['target_count']}\n")
                    log_file.write(f"  é…ç½®ã‚ªãƒãƒãƒˆãƒšæ•°: {placement_info['placed_count']}\n")
                    
                    for i, detail in enumerate(onomatopoeia_details, 1):
                        log_file.write(f"    ã‚ªãƒãƒãƒˆãƒš{i}: {detail['onomatopoeia_file']}\n")
                        log_file.write(f"      æœ€çµ‚ã‚µã‚¤ã‚º: {detail['final_size']}\n")
                        log_file.write(f"      é…ç½®ä½ç½®: {detail['position']}\n")
                        log_file.write(f"      ãƒ‘ãƒãƒ«: {detail.get('panel', 'N/A')}\n")
                        log_file.write(f"      ã‚¹ã‚±ãƒ¼ãƒ«: {detail['scale']}\n")
                    
                    log_file.write("\n")
                
                success_count += 1
                current_number += 1
                pbar.update(1)
            else:
                # é…ç½®å¤±æ•—
                with open(log_file_path, 'a', encoding='utf-8') as log_file:
                    log_file.write(f"âš ï¸ ã‚ªãƒãƒãƒˆãƒšé…ç½®å¤±æ•—: {page_name}\n\n")
            
            # æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸
            page_idx += 1
        
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ã¯ãƒ­ã‚°ã®ã¿ã«è¨˜éŒ²
            with open(log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(f"âŒ å‡¦ç†å¤±æ•—: {page_name} - {str(e)}\n\n")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸
            page_idx += 1
    
    pbar.close()
    print(f"âœ… {split_name} å®Œäº†: {success_count}å€‹ã®ç”»åƒã‚’ç”Ÿæˆ")
    print(f"ğŸ“„ è©³ç´°ãƒ­ã‚°: {log_file_path}")
    return success_count


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="ãƒ‘ãƒãƒ«å†…ã‚ªãƒãƒãƒˆãƒšåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µç‰ˆï¼‰")
    parser.add_argument("--onomatopoeia-dir", default="onomatopeias", help="ã‚ªãƒãƒãƒˆãƒšç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--mask-dir", default="onomatopeia_masks", help="ãƒã‚¹ã‚¯ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--page-dir", default="generated_double_backs_1536x1024", help="ãƒšãƒ¼ã‚¸ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--output-dir", default="onomatopoeia_dataset", help="åŸºæœ¬å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--dataset-name", type=str, default="1000-panel-aug", help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå")
    parser.add_argument("--target-images", type=int, default=1000, help="ç”Ÿæˆã™ã‚‹ç”»åƒæ•°")
    parser.add_argument("--train-ratio", type=float, default=0.8, help="trainç”¨ã®æ¯”ç‡")
    parser.add_argument("--no-augmentation", action="store_true", help="ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ç„¡åŠ¹åŒ–")
    
    args = parser.parse_args()
    
    # è¨­å®š
    CFG = {
        # èƒŒæ™¯ç”»åƒé¢ç©ã«å¯¾ã™ã‚‹ã‚ªãƒãƒãƒˆãƒšé¢ç©ã®æ¯”ç‡ (0.5%ã€œ3%)
        # ä¾‹: 1536x1024 = 1,572,864 ãƒ”ã‚¯ã‚»ãƒ«ã®å ´åˆ
        #   0.005 â†’ ç´„7,864 pxÂ² â†’ ç´„ 89x89
        #   0.03  â†’ ç´„47,186 pxÂ² â†’ ç´„ 217x217
        "SCALE_RANGE": (0.005, 0.03),
        
        # ã‚ªãƒãƒãƒˆãƒšå€‹æ•°ï¼ˆçµ±è¨ˆ: å¹³å‡7.2, ä¸­å¤®å€¤6, æ¨™æº–åå·®6.1, 25%ile=3, 75%ile=10ï¼‰
        "NUM_ONOMATOPOEIA_MEAN": 7.0,   # å¹³å‡
        "NUM_ONOMATOPOEIA_STD": 6.0,    # æ¨™æº–åå·®
        "NUM_ONOMATOPOEIA_MIN": 1,      # æœ€å°
        "NUM_ONOMATOPOEIA_MAX": 20,     # æœ€å¤§ï¼ˆç¾å®Ÿçš„ãªä¸Šé™ï¼‰
        
        "MAX_ATTEMPTS": 100,
        "MAX_ONOMATOPOEIA_PER_PANEL": 2,  # 1ãƒ‘ãƒãƒ«ã‚ãŸã‚Šã®æœ€å¤§ã‚ªãƒãƒãƒˆãƒšæ•°
        "TRAIN_RATIO": args.train_ratio,
        "ONOMATOPOEIA_SPLIT_SEED": 42,
        "PANEL_AREA_RATIO_THRESHOLD": 0.85,
        "PANEL_MIN_AREA": 10000,
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¨­å®š
        "AUGMENTATION": {
            "ENABLED": not args.no_augmentation,
            "ROTATION": True,
            "ROTATION_PROB": 0.7,
            "SCALE": True,
            "SCALE_PROB": 0.5,
            "ASPECT_RATIO": True,
            "ASPECT_PROB": 0.3,
            "SHEAR": True,
            "SHEAR_PROB": 0.4,
            "ALPHA": True,
            "ALPHA_PROB": 0.5,
            "BLUR": True,
            "BLUR_PROB": 0.3,
            "RANDOM_ERASING": False,  # ç„¡åŠ¹åŒ–ï¼ˆã‚ªãƒãƒãƒˆãƒšã«çŸ©å½¢æ¶ˆå»ã¯ä¸è‡ªç„¶ï¼‰
            "ERASING_PROB": 0.0,
        }
    }
    
    print("\n=== ãƒ‘ãƒãƒ«å†…ã‚ªãƒãƒãƒˆãƒšãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ä½œæˆé–‹å§‹ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µç‰ˆï¼‰ ===")
    print(f"ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ: {'æœ‰åŠ¹' if CFG['AUGMENTATION']['ENABLED'] else 'ç„¡åŠ¹'}")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    base_output_dir = args.output_dir
    dataset_name = args.dataset_name
    final_output_dir = os.path.join(base_output_dir, dataset_name)
    os.makedirs(base_output_dir, exist_ok=True)
    
    # è¨­å®šã‚’ä¿å­˜
    config_output = {
        "timestamp": datetime.now().isoformat(),
        "script_name": "create_onomatopoeia_panel_dataset_augmented.py",
        "dataset_name": dataset_name,
        "base_output_path": base_output_dir,
        "dataset_output_path": final_output_dir,
        "target_images": args.target_images,
        "config": CFG,
        "input_directories": {
            "onomatopoeia_dir": args.onomatopoeia_dir,
            "masks_dir": args.mask_dir,
            "pages_dir": args.page_dir
        }
    }
    
    config_file_path = os.path.join(base_output_dir, f"{dataset_name}_config.json")
    with open(config_file_path, 'w', encoding='utf-8') as f:
        json.dump(config_output, f, ensure_ascii=False, indent=2)
    print(f"è¨­å®šæƒ…å ±ã‚’ä¿å­˜: {config_file_path}")
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {final_output_dir}")
    
    # ã‚ªãƒãƒãƒˆãƒšã¨ãƒã‚¹ã‚¯ã®å¯¾å¿œã‚’å–å¾—
    onomatopoeia_mask_pairs = []
    print("\nã‚ªãƒãƒãƒˆãƒšãƒ»ãƒã‚¹ã‚¯ãƒšã‚¢ã‚’æ¤œç´¢ä¸­...")
    for onomatopoeia_file in os.listdir(args.onomatopoeia_dir):
        if onomatopoeia_file.endswith(('.png', '.jpg', '.jpeg')):
            onomatopoeia_path = os.path.join(args.onomatopoeia_dir, onomatopoeia_file)
            onomatopoeia_stem = Path(onomatopoeia_file).stem
            
            mask_file = f"{onomatopoeia_stem}_mask.png"
            mask_path = os.path.join(args.mask_dir, mask_file)
            
            if os.path.exists(mask_path):
                onomatopoeia_mask_pairs.append((onomatopoeia_path, mask_path))
    
    # ãƒšãƒ¼ã‚¸ç”»åƒã‚’å–å¾—
    page_files = []
    for page_file in os.listdir(args.page_dir):
        if page_file.endswith(('.png', '.jpg', '.jpeg')):
            page_files.append(os.path.join(args.page_dir, page_file))
    
    print(f"è¦‹ã¤ã‹ã£ãŸã‚ªãƒãƒãƒˆãƒš: {len(onomatopoeia_mask_pairs)}å€‹")
    print(f"è¦‹ã¤ã‹ã£ãŸãƒšãƒ¼ã‚¸: {len(page_files)}å€‹")
    
    # ã‚ªãƒãƒãƒˆãƒšãŒ0å€‹ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼çµ‚äº†
    if len(onomatopoeia_mask_pairs) == 0:
        print("\nâŒ ã‚¨ãƒ©ãƒ¼: ã‚ªãƒãƒãƒˆãƒšãƒ»ãƒã‚¹ã‚¯ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print(f"   ã‚ªãƒãƒãƒˆãƒšãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.onomatopoeia_dir}")
        print(f"   ãƒã‚¹ã‚¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.mask_dir}")
        print("\nç¢ºèªäº‹é …:")
        print("  1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹")
        print("  2. ã‚ªãƒãƒãƒˆãƒšç”»åƒï¼ˆ.png, .jpg, .jpegï¼‰ãŒå­˜åœ¨ã™ã‚‹ã‹")
        print("  3. å¯¾å¿œã™ã‚‹ãƒã‚¹ã‚¯ï¼ˆ<name>_mask.pngï¼‰ãŒå­˜åœ¨ã™ã‚‹ã‹")
        return
    
    # ãƒšãƒ¼ã‚¸ãŒ0å€‹ã®å ´åˆã‚‚ã‚¨ãƒ©ãƒ¼çµ‚äº†
    if len(page_files) == 0:
        print("\nâŒ ã‚¨ãƒ©ãƒ¼: ãƒšãƒ¼ã‚¸ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print(f"   ãƒšãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.page_dir}")
        return
    
    # ã‚ªãƒãƒãƒˆãƒšã‚’trainç”¨ã¨valç”¨ã«åˆ†å‰²
    print(f"\nã‚ªãƒãƒãƒˆãƒšã‚’åˆ†å‰²ä¸­ï¼ˆtrain:{CFG['TRAIN_RATIO']:.0%}, val:{1-CFG['TRAIN_RATIO']:.0%}ï¼‰...")
    train_onomatopoeia, val_onomatopoeia = split_onomatopoeia(
        onomatopoeia_mask_pairs,
        CFG["TRAIN_RATIO"],
        CFG["ONOMATOPOEIA_SPLIT_SEED"]
    )
    
    print(f"trainç”¨ã‚ªãƒãƒãƒˆãƒš: {len(train_onomatopoeia)}å€‹")
    print(f"valç”¨ã‚ªãƒãƒãƒˆãƒš: {len(val_onomatopoeia)}å€‹")
    
    # ç›®æ¨™ç”»åƒæ•°ã‚’è¨ˆç®—
    train_target = int(args.target_images * CFG["TRAIN_RATIO"])
    val_target = args.target_images - train_target
    
    print(f"\nç›®æ¨™ç”»åƒæ•°:")
    print(f"train: {train_target}æš")
    print(f"val: {val_target}æš")
    print(f"åˆè¨ˆ: {args.target_images}æš")
    
    # train ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
    train_img_dir = os.path.join(final_output_dir, "train", "images")
    train_mask_dir = os.path.join(final_output_dir, "train", "masks")
    os.makedirs(train_img_dir, exist_ok=True)
    os.makedirs(train_mask_dir, exist_ok=True)
    
    train_count = generate_dataset_split(
        page_files, train_onomatopoeia,
        train_img_dir, train_mask_dir, "train", train_target,
        CFG, final_output_dir
    )
    
    # val ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
    val_img_dir = os.path.join(final_output_dir, "val", "images")
    val_mask_dir = os.path.join(final_output_dir, "val", "masks")
    os.makedirs(val_img_dir, exist_ok=True)
    os.makedirs(val_mask_dir, exist_ok=True)
    
    val_count = generate_dataset_split(
        page_files, val_onomatopoeia,
        val_img_dir, val_mask_dir, "val", val_target,
        CFG, final_output_dir
    )
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\n=== ãƒ‘ãƒãƒ«å†…ã‚ªãƒãƒãƒˆãƒšãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ä½œæˆå®Œäº† ===")
    print(f"å‡ºåŠ›å…ˆ: {final_output_dir}")
    print(f"ç·ç”Ÿæˆç”»åƒæ•°: {train_count + val_count}æš")
    
    # çµ±è¨ˆæƒ…å ±
    stats = {
        "total_images": train_count + val_count,
        "train_images": train_count,
        "val_images": val_count,
        "train_onomatopoeia_used": len(train_onomatopoeia),
        "val_onomatopoeia_used": len(val_onomatopoeia),
        "total_pages_available": len(page_files),
        "total_onomatopoeia_pairs_available": len(onomatopoeia_mask_pairs),
        "augmentation_enabled": CFG['AUGMENTATION']['ENABLED']
    }
    
    for split in ["train", "val"]:
        img_count = len(list(Path(final_output_dir).glob(f"{split}/images/*.png")))
        mask_count = len(list(Path(final_output_dir).glob(f"{split}/masks/*.png")))
        print(f"{split}: {img_count} ç”»åƒ, {mask_count} ãƒã‚¹ã‚¯")
    
    # çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜
    config_output["statistics"] = stats
    with open(config_file_path, 'w', encoding='utf-8') as f:
        json.dump(config_output, f, ensure_ascii=False, indent=2)
    
    print(f"\nè¨­å®šãƒ»çµ±è¨ˆæƒ…å ±: {config_file_path}")


if __name__ == "__main__":
    main()
