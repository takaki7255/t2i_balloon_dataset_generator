"""
ã‚ªãƒãƒãƒˆãƒšã‚’æ¼«ç”»èƒŒæ™¯ç”»åƒã«åˆæˆã—ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
create_syn_dataset.pyã®ã‚ªãƒãƒãƒˆãƒšç‰ˆ
"""

import cv2
import numpy as np
from pathlib import Path
import os
import random
import shutil
from tqdm import tqdm
import json
from datetime import datetime
import re
import argparse


def regions_overlap(region1: tuple, region2: tuple) -> bool:
    """2ã¤ã®é ˜åŸŸãŒé‡è¤‡ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    x1_min, y1_min, x1_max, y1_max = region1
    x2_min, y2_min, x2_max, y2_max = region2
    
    return not (x1_max <= x2_min or x2_max <= x1_min or y1_max <= y2_min or y2_max <= y1_min)


def calculate_overlap_area(region1: tuple, region2: tuple) -> int:
    """2ã¤ã®é ˜åŸŸã®é‡è¤‡é¢ç©ã‚’è¨ˆç®—"""
    x1_min, y1_min, x1_max, y1_max = region1
    x2_min, y2_min, x2_max, y2_max = region2
    
    overlap_x_min = max(x1_min, x2_min)
    overlap_y_min = max(y1_min, y2_min)
    overlap_x_max = min(x1_max, x2_max)
    overlap_y_max = min(y1_max, y2_max)
    
    if overlap_x_max <= overlap_x_min or overlap_y_max <= overlap_y_min:
        return 0
    
    return (overlap_x_max - overlap_x_min) * (overlap_y_max - overlap_y_min)


def get_mask_bbox(mask):
    """ãƒã‚¹ã‚¯ã®éã‚¼ãƒ­é ˜åŸŸã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—"""
    coords = np.column_stack(np.where(mask > 0))
    
    if len(coords) == 0:
        return 0, 0, mask.shape[1], mask.shape[0]
    
    y_min, x_min = coords.min(axis=0)
    y_max, x_max = coords.max(axis=0)
    
    return x_min, y_min, x_max - x_min + 1, y_max - y_min + 1


def crop_onomatopoeia_and_mask(onomatopoeia, mask):
    """ãƒã‚¹ã‚¯ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦ã‚ªãƒãƒãƒˆãƒšç”»åƒã¨ãƒã‚¹ã‚¯ã‚’ã‚¯ãƒ­ãƒƒãƒ—"""
    x, y, w, h = get_mask_bbox(mask)
    
    cropped_onomatopoeia = onomatopoeia[y:y+h, x:x+w]
    cropped_mask = mask[y:y+h, x:x+w]
    
    return cropped_onomatopoeia, cropped_mask, (x, y, w, h)


def load_scale_stats(path: str) -> dict:
    """çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒ«çµ±è¨ˆæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ï¼‰"""
    stats = {
        "mean": None,
        "median": None,
        "std": None,
        "min": None,
        "max": None,
        "q25": None,
        "q75": None,
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹
        "bbox_mean": None,
        "bbox_median": None,
        "bbox_std": None,
        "bbox_q25": None,
        "bbox_q75": None,
        "type": "bbox"  # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨
    }
    
    try:
        with open(path, encoding="utf-8") as f:
            content = f.read()
        
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹çµ±è¨ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
        in_bbox_section = False
        for line in content.split('\n'):
            if "Bounding Box Size Ratio Statistics:" in line:
                in_bbox_section = True
                continue
            if in_bbox_section:
                if "Area Statistics" in line:
                    break
                
                if "Mean:" in line:
                    stats["bbox_mean"] = float(line.split("Mean:")[1].strip())
                elif "Median:" in line:
                    stats["bbox_median"] = float(line.split("Median:")[1].strip())
                elif "Standard deviation:" in line:
                    stats["bbox_std"] = float(line.split("Standard deviation:")[1].strip())
                elif "25th percentile:" in line:
                    stats["bbox_q25"] = float(line.split("25th percentile:")[1].strip())
                elif "75th percentile:" in line:
                    stats["bbox_q75"] = float(line.split("75th percentile:")[1].strip())
        
        print(f"âœ“ ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹çµ±è¨ˆã‚’èª­ã¿è¾¼ã¿: {path}")
        print(f"  ä¸­å¤®å€¤: {stats['bbox_median']:.6f}, å¹³å‡: {stats['bbox_mean']:.6f}, æ¨™æº–åå·®: {stats['bbox_std']:.6f}")
        return stats
    except Exception as e:
        print(f"çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return stats


def sample_scale(bg_w: int, bw: int, cfg: dict) -> float:
    """çµ±è¨ˆæƒ…å ±ã«åŸºã¥ã„ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ï¼‰"""
    mode = cfg.get("SCALE_MODE", "uniform")
    if mode == "lognormal":
        clip_min, clip_max = cfg["SCALE_CLIP"]
        
        # çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ã—ãŸä¸­å¤®å€¤ã¨æ¨™æº–åå·®ã‚’ä½¿ç”¨
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã§è¨ˆç®—ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã‚ˆã‚Šç´„4å€å¤§ãã„ï¼‰
        scale_stats = cfg.get("SCALE_STATS", {})
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ä¸­å¤®å€¤: 0.001488ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ 0.000371 ã®ç´„4å€ï¼‰
        target_median = scale_stats.get("bbox_median", 0.001488)
        sigma = 0.8  # ã‚ˆã‚Šä¸­å¤®å€¤ã«è¿‘ã„åˆ†å¸ƒã«ã™ã‚‹
        
        mu = np.log(target_median)
        s = np.random.lognormal(mu, sigma)
        return float(np.clip(s, clip_min, clip_max))
    else:
        return random.uniform(*cfg["SCALE_RANGE"])


def calculate_area_based_size(crop_w: int, crop_h: int, bg_w: int, bg_h: int, 
                             target_scale: float, mask: np.ndarray = None,
                             max_w_ratio: float = 0.15, 
                             max_h_ratio: float = 0.15) -> tuple:
    """é¢ç©ãƒ™ãƒ¼ã‚¹ã®ãƒªã‚µã‚¤ã‚ºã‚µã‚¤ã‚ºè¨ˆç®—
    
    Args:
        crop_w, crop_h: ã‚¯ãƒ­ãƒƒãƒ—ã•ã‚ŒãŸç”»åƒã®å¹…ãƒ»é«˜ã•
        bg_w, bg_h: èƒŒæ™¯ç”»åƒã®å¹…ãƒ»é«˜ã•
        target_scale: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆèƒŒæ™¯é¢ç©æ¯”ï¼‰
        mask: ãƒã‚¹ã‚¯ç”»åƒï¼ˆãƒã‚¹ã‚¯é ˜åŸŸã®ã¿ã§é¢ç©ã‚’è¨ˆç®—ã™ã‚‹å ´åˆï¼‰
        max_w_ratio, max_h_ratio: æœ€å¤§ã‚µã‚¤ã‚ºæ¯”
    
    Returns:
        (new_w, new_h): ãƒªã‚µã‚¤ã‚ºå¾Œã®ã‚µã‚¤ã‚º
    """
    bg_area = bg_w * bg_h
    target_area = bg_area * target_scale
    
    # ãƒã‚¹ã‚¯é ˜åŸŸã‚’è€ƒæ…®ã—ãŸå ´åˆã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã¨ã¯ç•°ãªã‚‹æœ‰åŠ¹é¢ç©æ¯”ã‚’è¨ˆç®—
    if mask is not None:
        # ãƒã‚¹ã‚¯é ˜åŸŸã®ãƒ”ã‚¯ã‚»ãƒ«æ•°
        mask_pixels = np.count_nonzero(mask)
        crop_pixels = crop_w * crop_h
        
        if crop_pixels > 0:
            # æœ‰åŠ¹é¢ç©ã®æ¯”ç‡ï¼ˆãƒã‚¹ã‚¯é ˜åŸŸ / ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ï¼‰
            mask_ratio = mask_pixels / crop_pixels
        else:
            mask_ratio = 1.0
    else:
        mask_ratio = 1.0
    
    aspect_ratio = crop_h / crop_w
    
    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ãŸç†æƒ³ã‚µã‚¤ã‚º
    ideal_w = int(np.sqrt(target_area / aspect_ratio))
    ideal_h = int(np.sqrt(target_area * aspect_ratio))
    
    # æœ€å¤§ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆã‚ªãƒãƒãƒˆãƒšã¯å°ã•ã‚ï¼‰
    max_w = int(bg_w * max_w_ratio)
    max_h = int(bg_h * max_h_ratio)
    
    # åˆ¶é™ã«åˆã‚ã›ã¦èª¿æ•´
    scale_by_w = max_w / ideal_w if ideal_w > max_w else 1.0
    scale_by_h = max_h / ideal_h if ideal_h > max_h else 1.0
    adjust_scale = min(scale_by_w, scale_by_h)
    
    new_w = int(ideal_w * adjust_scale)
    new_h = int(ideal_h * adjust_scale)
    
    # æœ€å°ã‚µã‚¤ã‚ºç¢ºä¿
    new_w = max(new_w, 10)
    new_h = max(new_h, 10)
    
    return new_w, new_h


def sample_num_onomatopoeia(cfg: dict, max_available: int) -> int:
    """çµ±è¨ˆæƒ…å ±ã«åŸºã¥ã„ã¦ã‚ªãƒãƒãƒˆãƒšå€‹æ•°ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
    lower, upper = cfg.get("NUM_ONOMATOPOEIA_RANGE", (1, 10))
    n = None

    probs = cfg.get("COUNT_PROBS", None)
    if probs is not None:
        idx = np.arange(len(probs))
        n = int(np.random.choice(idx, p=probs))

    if n is None:
        n = random.randint(lower, upper)

    n = max(lower, n)
    n = min(max_available, n)
    if n <= 0:
        n = 1
    return n


def load_count_probs(path: str, drop_zero: bool = True):
    """çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å€‹æ•°ã®ç¢ºç‡åˆ†å¸ƒã‚’èª­ã¿è¾¼ã‚€"""
    # ã‚ªãƒãƒãƒˆãƒšçµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆ¥å½¢å¼ãªã®ã§ã€å¹³å‡ãƒ»æ¨™æº–åå·®ã‹ã‚‰æ­£è¦åˆ†å¸ƒã‚’ç”Ÿæˆ
    try:
        with open(path, encoding="utf-8") as f:
            content = f.read()
            
        # å¹³å‡ã¨æ¨™æº–åå·®ã‚’æŠ½å‡º
        mean_match = re.search(r"Mean:\s+([\d.]+)", content)
        std_match = re.search(r"Standard deviation:\s+([\d.]+)", content)
        
        if mean_match and std_match:
            mean = float(mean_match.group(1))
            std = float(std_match.group(1))
            
            # æ­£è¦åˆ†å¸ƒã«åŸºã¥ãç¢ºç‡åˆ†å¸ƒã‚’ç”Ÿæˆï¼ˆ0-30ã®ç¯„å›²ï¼‰
            max_n = 30
            arr = np.zeros(max_n + 1, dtype=np.float32)
            
            for n in range(1, max_n + 1):
                # æ­£è¦åˆ†å¸ƒã®ç¢ºç‡å¯†åº¦
                arr[n] = np.exp(-0.5 * ((n - mean) / std) ** 2)
            
            if drop_zero:
                arr[0] = 0
            
            if arr.sum() > 0:
                probs = arr / arr.sum()
                return probs
    except Exception as e:
        print(f"çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    return None


def _json_default(o):
    """JSON serialization helper"""
    if isinstance(o, np.ndarray):
        return o.tolist()
    if isinstance(o, (np.integer, np.floating)):
        return o.item()
    if isinstance(o, Path):
        return str(o)
    return str(o)


def composite_random_onomatopoeia(background_path: str, onomatopoeia_mask_pairs: list,
                                 cfg: dict = None) -> tuple:
    """èƒŒæ™¯ç”»åƒã«ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ãŸè¤‡æ•°ã®ã‚ªãƒãƒãƒˆãƒšã‚’é‡è¤‡ãªã—ã§åˆæˆã™ã‚‹"""
    if cfg is None:
        cfg = {}
        
    # èƒŒæ™¯ç”»åƒèª­ã¿è¾¼ã¿
    background = cv2.imread(background_path, cv2.IMREAD_COLOR)
    if background is None:
        raise FileNotFoundError(f"èƒŒæ™¯ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {background_path}")
    
    bg_h, bg_w = background.shape[:2]
    result_img = background.copy()
    result_mask = np.zeros((bg_h, bg_w), dtype=np.uint8)
    
    # é…ç½®ã™ã‚‹ã‚ªãƒãƒãƒˆãƒšæ•°ã‚’çµ±è¨ˆæƒ…å ±ã«åŸºã¥ã„ã¦æ±ºå®š
    max_onomatopoeia = min(cfg.get("NUM_ONOMATOPOEIA_RANGE", (1, 10))[1], len(onomatopoeia_mask_pairs))
    num_onomatopoeia = sample_num_onomatopoeia(cfg, max_onomatopoeia)
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚ªãƒãƒãƒˆãƒšã‚’é¸æŠ
    selected_pairs = random.sample(onomatopoeia_mask_pairs, num_onomatopoeia)
    
    # é…ç½®æ¸ˆã¿é ˜åŸŸã‚’è¨˜éŒ²ã™ã‚‹é…åˆ—
    occupied_regions = []
    successfully_placed = []
    onomatopoeia_details = []
    
    # ã‚¹ã‚±ãƒ¼ãƒ«çµ±è¨ˆæƒ…å ±
    scale_stats = cfg.get("SCALE_STATS", {})
    
    for onomatopoeia_path, mask_path in selected_pairs:
        # ã‚ªãƒãƒãƒˆãƒšã¨ãƒã‚¹ã‚¯èª­ã¿è¾¼ã¿
        onomatopoeia = cv2.imread(onomatopoeia_path, cv2.IMREAD_COLOR)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        
        if onomatopoeia is None or mask is None:
            continue
        
        # ãƒã‚¹ã‚¯ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã§ã‚¯ãƒ­ãƒƒãƒ—
        cropped_onomatopoeia, cropped_mask, bbox = crop_onomatopoeia_and_mask(onomatopoeia, mask)
        
        if cropped_onomatopoeia.size == 0 or cropped_mask.size == 0:
            continue

        crop_h, crop_w = cropped_onomatopoeia.shape[:2]
        
        # çµ±è¨ˆæƒ…å ±ã«åŸºã¥ãã‚¹ã‚±ãƒ¼ãƒ«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        try:
            onomatopoeia_scale = sample_scale(bg_w, crop_w, cfg)
        except KeyError:
            onomatopoeia_scale = random.uniform(cfg.get("SCALE_RANGE", (0.0001, 0.002))[0], 
                                              cfg.get("SCALE_RANGE", (0.0001, 0.002))[1])
        
        # é¢ç©ãƒ™ãƒ¼ã‚¹ã®ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆãƒã‚¹ã‚¯é ˜åŸŸã‚’è€ƒæ…®ï¼‰
        new_onomatopoeia_w, new_onomatopoeia_h = calculate_area_based_size(
            crop_w, crop_h, bg_w, bg_h, onomatopoeia_scale,
            mask=cropped_mask,  # ãƒã‚¹ã‚¯é ˜åŸŸã‚’è€ƒæ…®
            max_w_ratio=cfg.get("MAX_WIDTH_RATIO", 0.15),
            max_h_ratio=cfg.get("MAX_HEIGHT_RATIO", 0.15)
        )
        
        # èƒŒæ™¯ã‚µã‚¤ã‚ºã‚’è¶…ãˆã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if new_onomatopoeia_w >= bg_w or new_onomatopoeia_h >= bg_h:
            continue
        
        # ã‚¯ãƒ­ãƒƒãƒ—ã•ã‚ŒãŸç”»åƒã‚’ãƒªã‚µã‚¤ã‚º
        onomatopoeia_resized = cv2.resize(cropped_onomatopoeia, (new_onomatopoeia_w, new_onomatopoeia_h))
        mask_resized = cv2.resize(cropped_mask, (new_onomatopoeia_w, new_onomatopoeia_h))
        
        # é‡è¤‡ã‚’é¿ã‘ã¤ã¤ä½ç½®ã‚’æ¢ã™
        placed = False
        best_position = None
        min_overlap_ratio = float('inf')
        
        # ã¾ãšé‡è¤‡å›é¿ã‚’è©¦è¡Œ
        max_attempts = cfg.get("MAX_ATTEMPTS", 200)
        for attempt in range(max_attempts // 2):
            max_x = max(0, bg_w - new_onomatopoeia_w)
            max_y = max(0, bg_h - new_onomatopoeia_h)
            
            if max_x <= 0 or max_y <= 0:
                break
                
            x = random.randint(0, max_x)
            y = random.randint(0, max_y)
            
            # æ–°ã—ã„é ˜åŸŸ
            new_region = (x, y, x + new_onomatopoeia_w, y + new_onomatopoeia_h)
            
            # æ—¢å­˜é ˜åŸŸã¨ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
            max_overlap_ratio = 0
            for occupied in occupied_regions:
                if regions_overlap(new_region, occupied):
                    overlap_area = calculate_overlap_area(new_region, occupied)
                    new_area = new_onomatopoeia_w * new_onomatopoeia_h
                    overlap_ratio = overlap_area / new_area
                    max_overlap_ratio = max(max_overlap_ratio, overlap_ratio)
            
            # é‡è¤‡ãŒå°‘ãªã„å ´åˆã¯é…ç½®
            if max_overlap_ratio <= 0.15:
                best_position = (x, y)
                placed = True
                break
            
            # ã‚ˆã‚Šè‰¯ã„ä½ç½®ã‚’è¨˜éŒ²
            if max_overlap_ratio < min_overlap_ratio:
                min_overlap_ratio = max_overlap_ratio
                best_position = (x, y)
        
        # é‡è¤‡å›é¿ã«å¤±æ•—ã—ãŸå ´åˆã€æœ€ã‚‚é‡è¤‡ã®å°‘ãªã„ä½ç½®ã«é…ç½®
        if not placed and best_position is not None:
            x, y = best_position
            placed = True
        
        # æœ€çµ‚çš„ã«ãƒ©ãƒ³ãƒ€ãƒ ä½ç½®ã«é…ç½®ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if not placed:
            max_x = max(0, bg_w - new_onomatopoeia_w)
            max_y = max(0, bg_h - new_onomatopoeia_h)
            if max_x >= 0 and max_y >= 0:
                x = random.randint(0, max_x) if max_x > 0 else 0
                y = random.randint(0, max_y) if max_y > 0 else 0
                placed = True
        
        if placed:
            # åˆæˆå®Ÿè¡Œ
            mask_norm = mask_resized.astype(np.float32) / 255.0
            mask_3ch = cv2.merge([mask_norm, mask_norm, mask_norm])
            
            # èƒŒæ™¯ç”»åƒã®è©²å½“é ˜åŸŸ
            bg_region = result_img[y:y+new_onomatopoeia_h, x:x+new_onomatopoeia_w]
            
            # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
            blended = onomatopoeia_resized.astype(np.float32) * mask_3ch + bg_region.astype(np.float32) * (1 - mask_3ch)
            result_img[y:y+new_onomatopoeia_h, x:x+new_onomatopoeia_w] = blended.astype(np.uint8)
            
            # ãƒã‚¹ã‚¯ã‚‚åˆæˆ
            result_mask[y:y+new_onomatopoeia_h, x:x+new_onomatopoeia_w] = np.maximum(
                result_mask[y:y+new_onomatopoeia_h, x:x+new_onomatopoeia_w], mask_resized)
            
            # é…ç½®æ¸ˆã¿é ˜åŸŸã«è¿½åŠ 
            new_region = (x, y, x + new_onomatopoeia_w, y + new_onomatopoeia_h)
            occupied_regions.append(new_region)
            successfully_placed.append(Path(onomatopoeia_path).stem)
            
            # è©³ç´°æƒ…å ±ã‚’è¨˜éŒ²
            onomatopoeia_info = {
                "onomatopoeia_file": Path(onomatopoeia_path).name,
                "original_size": f"{onomatopoeia.shape[1]}x{onomatopoeia.shape[0]}",
                "cropped_size": f"{crop_w}x{crop_h}",
                "final_size": f"{new_onomatopoeia_w}x{new_onomatopoeia_h}",
                "position": f"({x},{y})",
                "scale": f"{onomatopoeia_scale:.6f}",
                "scale_ratio": f"{new_onomatopoeia_w/bg_w:.4f}"
            }
            onomatopoeia_details.append(onomatopoeia_info)
    
    return result_img, result_mask, successfully_placed, onomatopoeia_details


def split_onomatopoeia(onomatopoeia_mask_pairs: list, train_ratio: float = 0.8, seed: int = 42) -> tuple:
    """ã‚ªãƒãƒãƒˆãƒšã‚’trainç”¨ã¨valç”¨ã«åˆ†å‰²ã™ã‚‹"""
    random.seed(seed)
    shuffled_pairs = onomatopoeia_mask_pairs.copy()
    random.shuffle(shuffled_pairs)
    
    n = len(shuffled_pairs)
    train_count = int(n * train_ratio)
    
    train_pairs = shuffled_pairs[:train_count]
    val_pairs = shuffled_pairs[train_count:]
    
    return train_pairs, val_pairs


def generate_dataset_split(background_files: list, onomatopoeia_pairs: list, 
                          output_dir: str, mask_output_dir: str, split_name: str,
                          target_count: int, cfg: dict, final_output_dir: str = None) -> int:
    """æŒ‡å®šã•ã‚ŒãŸsplitï¼ˆtrainã¾ãŸã¯valï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    print(f"\n=== {split_name} ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆé–‹å§‹ ===")
    print(f"ç›®æ¨™ç”»åƒæ•°: {target_count}")
    print(f"èƒŒæ™¯ç”»åƒæ•°: {len(background_files)}")
    print(f"åˆ©ç”¨å¯èƒ½ã‚ªãƒãƒãƒˆãƒšæ•°: {len(onomatopoeia_pairs)}")
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    if final_output_dir:
        log_file_path = os.path.join(final_output_dir, f"{split_name}_composition_log.txt")
    else:
        log_file_path = os.path.join(output_dir, f"{split_name}_composition_log.txt")
    
    current_number = 1
    success_count = 0
    bg_idx = 0
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸåŒ–
    with open(log_file_path, 'w', encoding='utf-8') as log_file:
        log_file.write(f"=== {split_name.upper()} ã‚ªãƒãƒãƒˆãƒšãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆæˆãƒ­ã‚° ===\n")
        log_file.write(f"ç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        log_file.write(f"ç›®æ¨™ç”»åƒæ•°: {target_count}\n")
        log_file.write(f"èƒŒæ™¯ç”»åƒæ•°: {len(background_files)}\n")
        log_file.write(f"åˆ©ç”¨å¯èƒ½ã‚ªãƒãƒãƒˆãƒšæ•°: {len(onomatopoeia_pairs)}\n")
        log_file.write("=" * 80 + "\n\n")
    
    # ç›®æ¨™æ•°ã«é”ã™ã‚‹ã¾ã§ç”Ÿæˆ
    while success_count < target_count:
        # èƒŒæ™¯ç”»åƒã‚’å¾ªç’°ä½¿ç”¨
        bg_path = background_files[bg_idx % len(background_files)]
        bg_name = Path(bg_path).stem
        
        try:
            # ã‚ªãƒãƒãƒˆãƒšåˆæˆå®Ÿè¡Œ
            result_img, result_mask, placed_onomatopoeia, onomatopoeia_details = composite_random_onomatopoeia(
                bg_path, 
                onomatopoeia_pairs,
                cfg=cfg
            )
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            output_img_path = os.path.join(output_dir, f"{current_number:03d}.png")
            output_mask_path = os.path.join(mask_output_dir, f"{current_number:03d}_mask.png")
            
            cv2.imwrite(output_img_path, result_img)
            cv2.imwrite(output_mask_path, result_mask)
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è©³ç´°æƒ…å ±ã‚’è¨˜éŒ²
            with open(log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(f"ç”»åƒ {current_number:03d}.png:\n")
                log_file.write(f"  èƒŒæ™¯ãƒ•ã‚¡ã‚¤ãƒ«: {Path(bg_path).name}\n")
                log_file.write(f"  èƒŒæ™¯ã‚µã‚¤ã‚º: {result_img.shape[1]}x{result_img.shape[0]}\n")
                log_file.write(f"  é…ç½®ã—ãŸã‚ªãƒãƒãƒˆãƒšæ•°: {len(onomatopoeia_details)}\n")
                
                for i, detail in enumerate(onomatopoeia_details, 1):
                    log_file.write(f"    ã‚ªãƒãƒãƒˆãƒš{i}: {detail['onomatopoeia_file']}\n")
                    log_file.write(f"      å…ƒã‚µã‚¤ã‚º: {detail['original_size']}\n")
                    log_file.write(f"      ã‚¯ãƒ­ãƒƒãƒ—ã‚µã‚¤ã‚º: {detail['cropped_size']}\n")
                    log_file.write(f"      æœ€çµ‚ã‚µã‚¤ã‚º: {detail['final_size']}\n")
                    log_file.write(f"      é…ç½®ä½ç½®: {detail['position']}\n")
                    log_file.write(f"      ã‚¹ã‚±ãƒ¼ãƒ«: {detail['scale']}\n")
                    log_file.write(f"      ã‚¹ã‚±ãƒ¼ãƒ«æ¯”: {detail['scale_ratio']}\n")
                
                log_file.write("\n")
            
            success_count += 1
            current_number += 1
            
            if success_count % 10 == 0:
                print(f"  é€²æ—: {success_count}/{target_count} å®Œäº†")
            
        except Exception as e:
            print(f"âœ— åˆæˆå¤±æ•— (èƒŒæ™¯:{bg_name}): {e}")
            with open(log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(f"âŒ åˆæˆå¤±æ•—: {bg_name} - {str(e)}\n\n")
        
        bg_idx += 1
    
    print(f"âœ… {split_name} å®Œäº†: {success_count}å€‹ã®ç”»åƒã‚’ç”Ÿæˆ")
    print(f"ğŸ“„ è©³ç´°ãƒ­ã‚°: {log_file_path}")
    return success_count


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="ã‚ªãƒãƒãƒˆãƒšåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ")
    parser.add_argument("--onomatopoeia-dir", default="onomatopeias", help="ã‚ªãƒãƒãƒˆãƒšç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--mask-dir", default="onomatopeia_masks", help="ãƒã‚¹ã‚¯ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--background-dir", default="generated_double_backs", help="èƒŒæ™¯ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--output-dir", default="onomatopeia_datasets", help="åŸºæœ¬å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--dataset-name", type=str, default="test", help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå (dataset01, train_v1ãªã©)")
    parser.add_argument("--target-images", type=int, default=100, help="ç”Ÿæˆã™ã‚‹ç”»åƒæ•°")
    parser.add_argument("--train-ratio", type=float, default=0.8, help="trainç”¨ã®æ¯”ç‡")
    
    args = parser.parse_args()
    
    # è¨­å®š
    CFG = {
        "SCALE_RANGE": (0.0001, 0.005),
        "NUM_ONOMATOPOEIA_RANGE": (1, 15),
        "MAX_ATTEMPTS": 200,
        "TRAIN_RATIO": args.train_ratio,
        "ONOMATOPOEIA_SPLIT_SEED": 42,
        
        # çµ±è¨ˆæƒ…å ±ãƒ™ãƒ¼ã‚¹ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¨­å®šï¼ˆãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ï¼‰
        "SCALE_MODE": "lognormal",
        "SCALE_MEAN": 0.005623,              # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹å¹³å‡é¢ç©æ¯”
        "SCALE_STD": 0.014176,               # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æ¨™æº–åå·®
        "SCALE_CLIP": (0.0005, 0.020),       # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ç¯„å›²ï¼ˆQ25-Maxä»˜è¿‘ï¼‰
        "COUNT_PROBS": None,                 # ã‚ªãƒãƒãƒˆãƒšå€‹æ•°ã®ç¢ºç‡åˆ†å¸ƒ
        "SCALE_STATS": None,                 # ã‚¹ã‚±ãƒ¼ãƒ«çµ±è¨ˆæƒ…å ±
        "COUNT_STATS_FILE": "onomatopoeia_statistics.txt",
        
        # é¢ç©ãƒ™ãƒ¼ã‚¹ãƒªã‚µã‚¤ã‚ºè¨­å®š
        "MAX_WIDTH_RATIO": 0.25,             # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ãªã®ã§æ‹¡å¤§
        "MAX_HEIGHT_RATIO": 0.25,            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ãªã®ã§æ‹¡å¤§
    }
    
    # çµ±è¨ˆæƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    if CFG.get("COUNT_STATS_FILE") and os.path.exists(CFG["COUNT_STATS_FILE"]):
        print(f"\nğŸ“Š çµ±è¨ˆæƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {CFG['COUNT_STATS_FILE']}")
        CFG["SCALE_STATS"] = load_scale_stats(CFG["COUNT_STATS_FILE"])
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆï¼ˆéšå±¤æ§‹é€ ï¼šonomatopeia_datasets/dataset01/ï¼‰
    base_output_dir = args.output_dir
    dataset_name = args.dataset_name
    final_output_dir = os.path.join(base_output_dir, dataset_name)
    os.makedirs(base_output_dir, exist_ok=True)
    
    # è¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    config_output = {
        "timestamp": datetime.now().isoformat(),
        "script_name": "create_syn_onomatopoeia_dataset.py",
        "dataset_name": dataset_name,
        "base_output_path": base_output_dir,
        "dataset_output_path": final_output_dir,
        "target_images": args.target_images,
        "config": CFG,
        "input_directories": {
            "onomatopoeia_dir": args.onomatopoeia_dir,
            "masks_dir": args.mask_dir,
            "backgrounds_dir": args.background_dir
        }
    }
    
    config_file_path = os.path.join(base_output_dir, f"{dataset_name}_config.json")
    with open(config_file_path, 'w', encoding='utf-8') as f:
        json.dump(config_output, f, ensure_ascii=False, indent=2, default=_json_default)
    print(f"è¨­å®šæƒ…å ±ã‚’ä¿å­˜: {config_file_path}")
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {final_output_dir}")
    
    # å€‹æ•°åˆ†å¸ƒã®èª­ã¿è¾¼ã¿
    try:
        CFG["COUNT_PROBS"] = load_count_probs(CFG["COUNT_STATS_FILE"])
        print(f"âœ“ çµ±è¨ˆãƒ™ãƒ¼ã‚¹ã®ã‚ªãƒãƒãƒˆãƒšå€‹æ•°ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–")
    except Exception as e:
        print(f"å€‹æ•°åˆ†å¸ƒã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print("ä¸€æ§˜ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    print("\n=== ã‚ªãƒãƒãƒˆãƒšãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ä½œæˆé–‹å§‹ ===")
    
    # ã‚ªãƒãƒãƒˆãƒšã¨ãƒã‚¹ã‚¯ã®å¯¾å¿œã‚’å–å¾—
    onomatopoeia_mask_pairs = []
    print("ã‚ªãƒãƒãƒˆãƒšãƒ»ãƒã‚¹ã‚¯ãƒšã‚¢ã‚’æ¤œç´¢ä¸­...")
    for onomatopoeia_file in os.listdir(args.onomatopoeia_dir):
        if onomatopoeia_file.endswith(('.png', '.jpg', '.jpeg')):
            onomatopoeia_path = os.path.join(args.onomatopoeia_dir, onomatopoeia_file)
            onomatopoeia_stem = Path(onomatopoeia_file).stem
            
            # å¯¾å¿œã™ã‚‹ãƒã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            mask_file = f"{onomatopoeia_stem}_mask.png"
            mask_path = os.path.join(args.mask_dir, mask_file)
            
            if os.path.exists(mask_path):
                onomatopoeia_mask_pairs.append((onomatopoeia_path, mask_path))
    
    # èƒŒæ™¯ç”»åƒã‚’å–å¾—
    background_files = []
    for bg_file in os.listdir(args.background_dir):
        if bg_file.endswith(('.png', '.jpg', '.jpeg')):
            background_files.append(os.path.join(args.background_dir, bg_file))
    
    print(f"è¦‹ã¤ã‹ã£ãŸã‚ªãƒãƒãƒˆãƒš: {len(onomatopoeia_mask_pairs)}å€‹")
    print(f"è¦‹ã¤ã‹ã£ãŸèƒŒæ™¯: {len(background_files)}å€‹")
    
    # ã‚ªãƒãƒãƒˆãƒšã‚’trainç”¨ã¨valç”¨ã«åˆ†å‰²
    print(f"\nã‚ªãƒãƒãƒˆãƒšã‚’åˆ†å‰²ä¸­ï¼ˆtrain:{CFG['TRAIN_RATIO']:.0%}, val:{1-CFG['TRAIN_RATIO']:.0%}ï¼‰...")
    train_onomatopoeia, val_onomatopoeia = split_onomatopoeia(
        onomatopoeia_mask_pairs, 
        CFG["TRAIN_RATIO"], 
        CFG["ONOMATOPOEIA_SPLIT_SEED"]
    )
    
    print(f"trainç”¨ã‚ªãƒãƒãƒˆãƒš: {len(train_onomatopoeia)}å€‹")
    print(f"valç”¨ã‚ªãƒãƒãƒˆãƒš: {len(val_onomatopoeia)}å€‹")
    
    # ç›®æ¨™ç”»åƒæ•°ã‚’è¨ˆç®—
    train_target = int(args.target_images * CFG["TRAIN_RATIO"])
    val_target = args.target_images - train_target
    
    print(f"\nç›®æ¨™ç”»åƒæ•°:")
    print(f"train: {train_target}æš")
    print(f"val: {val_target}æš")
    print(f"åˆè¨ˆ: {args.target_images}æš")
    
    # train ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
    train_img_dir = os.path.join(final_output_dir, "train", "images")
    train_mask_dir = os.path.join(final_output_dir, "train", "masks")
    os.makedirs(train_img_dir, exist_ok=True)
    os.makedirs(train_mask_dir, exist_ok=True)
    
    train_count = generate_dataset_split(
        background_files, train_onomatopoeia,
        train_img_dir, train_mask_dir, "train", train_target, 
        CFG, final_output_dir
    )
    
    # val ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
    val_img_dir = os.path.join(final_output_dir, "val", "images")
    val_mask_dir = os.path.join(final_output_dir, "val", "masks")
    os.makedirs(val_img_dir, exist_ok=True)
    os.makedirs(val_mask_dir, exist_ok=True)
    
    val_count = generate_dataset_split(
        background_files, val_onomatopoeia,
        val_img_dir, val_mask_dir, "val", val_target, 
        CFG, final_output_dir
    )
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\n=== ã‚ªãƒãƒãƒˆãƒšãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ä½œæˆå®Œäº† ===")
    print(f"å‡ºåŠ›å…ˆ: {final_output_dir}")
    print(f"ç·ç”Ÿæˆç”»åƒæ•°: {train_count + val_count}æš")
    
    # çµ±è¨ˆæƒ…å ±ã‚’åé›†
    stats = {
        "total_images": train_count + val_count,
        "train_images": train_count,
        "val_images": val_count,
        "train_onomatopoeia_used": len(train_onomatopoeia),
        "val_onomatopoeia_used": len(val_onomatopoeia),
        "total_backgrounds_available": len(background_files),
        "total_onomatopoeia_pairs_available": len(onomatopoeia_mask_pairs)
    }
    
    # çµ±è¨ˆã‚’è¡¨ç¤º
    for split in ["train", "val"]:
        img_count = len(list(Path(final_output_dir).glob(f"{split}/images/*.png")))
        mask_count = len(list(Path(final_output_dir).glob(f"{split}/masks/*.png")))
        print(f"{split}: {img_count} ç”»åƒ, {mask_count} ãƒã‚¹ã‚¯")
    
    # çµ±è¨ˆæƒ…å ±ã‚’config.jsonã«è¿½åŠ 
    config_output["statistics"] = stats
    with open(config_file_path, 'w', encoding='utf-8') as f:
        json.dump(config_output, f, ensure_ascii=False, indent=2, default=_json_default)
    
    print(f"\n=== ã‚ªãƒãƒãƒˆãƒšä½¿ç”¨çŠ¶æ³ ===")
    print(f"trainç”¨ã‚ªãƒãƒãƒˆãƒš: {len(train_onomatopoeia)}å€‹")
    print(f"valç”¨ã‚ªãƒãƒãƒˆãƒš: {len(val_onomatopoeia)}å€‹")
    print(f"é‡è¤‡ãªã—: train ã¨ val ã§ç•°ãªã‚‹ã‚ªãƒãƒãƒˆãƒšã‚’ä½¿ç”¨")
    print(f"è¨­å®šãƒ»çµ±è¨ˆæƒ…å ±: {config_file_path}")


if __name__ == "__main__":
    main()
